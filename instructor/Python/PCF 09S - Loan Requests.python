{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "61bb4825-3e6d-42a3-add9-96f448cd5ca7", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "2327298b-46ae-403c-b3c2-8f8c6aa21e9d", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\n# Bronze To Silver - Loan Requests\n\nThere are several minor issues in the Loan Requests bronze table. Let's fix them!\n\n## In this exercise you will:\n* Be introduced to a hashing function you can use to encrypt sensitive information\n* Practice joining DataFrames\n* Practice how to cast timestamps to timestamp type\n* Learn how to filter DataFrames based on lists of items\n* Practice how to express conditions with `when` and `otherwise`\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 7.0**", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "20b151c9-370e-426f-a49f-bae8ab682d67", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "674cedf5-2be2-4cb4-b40e-37d78f9b6ed0", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<h2 style=\"color:red\">Instructor Note</h2>\n\n\n\nThings to talk about:\n- mention that we're working with silver tables\n- talk about the goal:\n  - what are we building right now: we're fixing loan requests table while also extending it\n  - why is it useful: generating flags will help later on in filtering and computing statistics\n- hashing concept if the audience is not familiar with it\n- .isin() method and using non-spark objects with spark\n- talk about when-otherwise function if the participants are not familiar with them\n- reiterate on the importance of hashing\n- emphasize the importance of using built-in functions\n- encourage the participants to build columnar expressions outside of the query and save them to variables\n- the importance of the flags", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "fedbd93c-dc0d-4fd7-aed7-351dbe2c691a", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "cc22954e-7f41-4a90-a1b0-596e3ce45df6", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "f80e26f2-0f04-4e5c-bf82-5d09b4949513", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "5228073a-276e-4900-8f57-679316bd6068", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/PCF-09S-ClassroomSetup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "24aea5dc-d378-4906-9f56-55142639b1e5", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "88249c48-d488-431e-b049-701630ad782a", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Steps to complete<br>\nImplement the **`challenge()`** function to achieve the following:\n- Read the _Loan Requests_ bronze table from **`loanRequestsPath`**.\n- Convert the **`request_time`** and **`valid_to`** fields to timestamp.\n- Take a look at the data. There is a **`password`** field containing sensitive information. \n  Let's get this encrypted before the data hits the gold layer. \n  Create a new column called **`password_hash`** and set the column values to the <a href='https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.md5' target='_blank'>MD5 hash</a> of passwords.\n  Once the hashing is done, drop the **`password`** column.\n- Since the loan request module has recently experienced a glitch, some request amounts are blank empty strings. \n  Replace **`request_amount`**  with nulls and add a new _True/False_ column called **`missing_amount`**. \n  Set the **`missing_amount`** value so that it indicates whether or not the amount was left blank.\n- There are a few blacklisted investors. They are stored in a native list (not a DataFrame) called **`banned_investor_list`**, which was preloaded for you. \n  Create a new boolean column called **`banned_investor`** and indicate whether the investor of the respective request is a listed in **`banned_investor_list`**.\n- Read the Investors silver table from the  **`investorsPath`** into a DataFrame.\n- Join the Loan Requests you worked on with the Investors using a left join.\n- Now create a new column called **`loan_alert`** in the joined DataFrame. Set its value to **`red`** if the **`credit_score`** is smaller than or equal to 1. Otherwise set the value to **`green`**.\n- Write the resulting DataFrame as a Delta table to **`targetDirectory`**.\n- Return the final DataFrame.\n\n<p> The resulting DataFrame's expected schema is:\n  \n|name|type|\n|---|---|\n|investor_id|LongType|\n|loan_id|LongType|\n|product_id|LongType|\n|request_amount|StringType|\n|request_length|LongType|\n|request_time|TimestampType|\n|valid_to|TimestampType|\n|password_hash|StringType|\n|missing_amount|BooleanType|\n|banned_investor|BooleanType|\n|loan_alert|StringType|\n  ", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "7428dadf-436f-4697-8603-6a7254992459", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "9eb93d93-dacd-47e1-aa0d-5a48c2d9b399", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "# ANSWER\n\ndef solution(spark, loanRequestsPath, investorsPath, targetDirectory):\n  from pyspark.sql.functions import col, md5, when, trim\n  \n  # Read the _Loan Requests_ bronze table from `loanRequestsPath`\n  # Convert the `request_time` and `valid_to` fields to timestamp.\n  loanRequests = (spark.read.format(\"delta\").load(loanRequestsPath)\n                  .withColumn(\"request_time\", col(\"request_time\").cast(\"timestamp\"))\n                  .withColumn(\"valid_to\", col(\"valid_to\").cast(\"timestamp\"))\n                  )\n  \n  # Create a new column called `password_hash` and set the column values to MD5 hash. Once the hashing is done, drop the `password` column.\n  res = (loanRequests\n       .withColumn(\"password_hash\", md5(col(\"password\"))).drop(col(\"password\")))\n  \n  # Some request amounts are blank empty strings. Replace them with nulls and add a new True/False column called `missing_amount` \n  res = res.withColumn(\"request_amount\", when(col(\"request_amount\") == \"\", None).otherwise(col(\"request_amount\")))\n  res = res.withColumn(\"missing_amount\", col(\"request_amount\").isNull())\n  \n  # Create a new boolean column called `banned_investor` and indicate whether the investor of the respective request is a blacklisted investor.\n  res = res.withColumn(\"banned_investor\", res[\"investor_id\"].isin(banned_investor_list))\n  \n  # Read the Investors silver table from the  `investorsPath` into a DataFrame.\n  investors = spark.read.format(\"delta\").load(investorsPath).select(\"investor_id\",\"credit_score\")\n\n  # Join the Loan Requests you worked on with the Investors using a left join.\n  # Now create a new column called `loan_alert` in the joined DataFrame. \n  # Set its value to \"red\" if the `credit_score` is smaller than or equal to 1. Otherwise set the value to \"green\"\n  res = (res\n        .join(investors, on=\"investor_id\", how=\"left\")\n        .withColumn(\"loan_alert\", when(col(\"credit_score\") <= 1, \"red\").otherwise(\"green\"))\n        .drop(\"credit_score\"))\n  \n  # Write the resulting DataFrame as a Delta table to `targetDirectory` with overwrite mode and overwrite schema option\n  res.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", True).save(targetDirectory)\n  \n  # Return the final DataFrame.\n  return res\n\nsolutionDF = solution(spark, loanRequestsPath, investorsPath, targetDirectory)\ndisplay(solutionDF)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "2c340697-78e9-45c0-a98f-d33e74adb1a5", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "47531870-914c-4902-b624-b04989d3b46b", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Reality Check</h2>\n\nRun the following cell to make sure you are on track:", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "40e8bccb-36ad-4e20-89d0-e6479e898dea", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "30496fd4-22d1-49cb-bbfc-492d47a7f130", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "# ANSWER - Test your solution\nrealityCheck(solution, spark, loanRequestsPath, investorsPath, targetDirectory)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "de08aedb-30ce-43b4-b016-57b1716c93db", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "830b2224-bd42-4d62-af90-3ce5591d171c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "6cf0b031-7525-4b14-8bac-448759ad2b50", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "54c16d7c-8c8e-476c-93df-ff7f6909d996", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 10, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/Classroom-Cleanup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "ba8f218c-336a-4727-b62e-846e62aeaaf0", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "affd87b1-dc52-4726-a1ac-097d9aa1d543", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 11, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## <img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps\n\nStart the next challenge, [Loan Requests 2]($./PCF 10S - Loan Requests 2)\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "545a500e-e5f1-44af-9c29-647bdee8df83", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d1195ab8-9a42-40b0-af5b-5a19e8055a64", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 12, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "89c609b9-021e-4279-917a-bd39f5fbd1ef", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "1f5979a8-b6f3-4492-9dc4-beec5b6daf05", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 13, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "b14eb01e-0d4b-4993-a054-32515698079f", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "PCF 09S - Loan Requests", "origId": 0, "version": "NotebookV1"}