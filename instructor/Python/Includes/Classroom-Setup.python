{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%python\n# We need the python version of financeDataPath in 03B - it has an ALL_NOTEBOOKS Python code which needs to be execute\n# There shouldn't be anything else in this cell that would vary between Python and Scala doing this to the whole cell should be OK\n\nfinanceDataPath = \"dbfs:/mnt/training/finance-org\"\n\nspark.conf.set(\"com.databricks.training.module-name\", \"capstone-finance\")\n\nspark.conf.set(\"com.databricks.training.suppress.untilStreamIsReady\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.stopAllStreams\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.moduleName\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.lessonName\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.username\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.userhome\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.workingDir\", \"true\")\n\ndisplayHTML(\"Preparing the learning environment...\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "92840ed4-2c88-4c3f-b2e6-13a35b2751c0", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "821db4d1-b7b9-4e91-9dee-cebd46e40087", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Common-Notebooks/Common", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "6b4624b1-2da9-4162-a13b-9a4bc583ae1e", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "882207d9-7fa2-4363-b728-a4caf63bee2c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "courseAdvertisements[\"financeDataPath\"] = (\"v\", financeDataPath, \"The location of the finance dataset used in this capstone project.\")\n\nsourceDataPath = financeDataPath + \"/solutions\"\ncourseAdvertisements[\"sourceDataPath\"] = (\"v\", sourceDataPath, \"The location of the specific datasets used in this capstone project as source data.\")\n\nimport pyspark\n\n# This should be commented out by default. Use if only when developing the courseware.\n# This function recreates notebook target datasets as reference datasets.\n\ndef updateSourceDataInDevMode(df, pathSuffix):\n  return\n  path = sourceDataPath + \"/\" + pathSuffix\n  dbutils.fs.rm(path, True)\n  df.write.mode(\"overwrite\").option(\"overwriteSchema\", True).format(\"delta\").save(path)\n\n  displayHTML(\"\"\"\n  <div style=\"padding:1em; border: 5px solid red\">\n      <div>Recreated dataset from reference data: \"\"\" + path + \"\"\"</div>\n  </div>\n\"\"\")\n  \ndef roundDataFrame(df):\n  res = df\n  for c in df.schema:\n    if ((c.dataType == pyspark.sql.types.DoubleType()) \n        or (c.dataType == pyspark.sql.types.FloatType())):\n      res = res.withColumn(c.name, pyspark.sql.functions.floor(pyspark.sql.functions.col(c.name)))\n  return res\n\ndef compareDataFramesLimited(df1:pyspark.sql.DataFrame, df2:pyspark.sql.DataFrame) -> bool:\n  sortedColumns1 = sorted(df1.columns)\n  df1Sorted = df1.select(sortedColumns1).orderBy(sortedColumns1).limit(10000)\n  \n  sortedColumns2 = sorted(df2.columns)\n  df2Sorted = df2.select(sortedColumns2).orderBy(sortedColumns2).limit(10000)\n\n  return compareDataFrames(roundDataFrame(df1Sorted), roundDataFrame(df2Sorted), testColumnOrder=True, testNullable=False)\n\ndisplayHTML(\"Finalizing the learning environment...\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "a555e229-3130-44cf-86b1-b0795b30b5a5", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "df454c4f-93fc-4910-8817-dbf5c53fc488", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "2dd190d1-237a-42c8-a21e-a905b36e973a", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "Classroom-Setup", "origId": 0, "version": "NotebookV1"}