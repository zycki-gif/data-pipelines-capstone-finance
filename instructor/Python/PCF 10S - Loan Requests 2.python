{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "68056bea-6710-4021-82d9-779576376769", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "fd0656da-a042-475c-9c23-d585f9233c6a", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\n# Bronze To Silver - Loan Requests 2\n\nLet's standardize the **`request_amount`** format in Purchase Orders and write two DataFrames to two different paths: one for loan requests without any problems and another for loan requests with missing amounts or blacklisted inverstors in need of manual checks  executed by our staff.\n\n\n## In this exercise you will:\n* Learn about User Defined Functions (UDFs)\n* Practice using performant built-in functions\n* Practice using filters with OR predicate\n* Practice using regular expressions \n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 7.0**", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "42f970a9-acb4-48a3-adb0-c07362577661", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "8e7d5f04-3662-48a5-b663-95cc77fe1c7b", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<h2 style=\"color:red\">Instructor Note</h2>\n\n\n\nThings to talk about:\n- talk about the goal:\n  - what are we building right now: standardizing values in loan requests table and separating rows for manual checking\n  - why is it useful: sometimes losing rows is not feasable; we'll use the manually fixed data later on\n- describe how udfs are executed\n- emphasize the importance of using built-in functions\n- compare built-in and udf solutions\n- talk about when to use udfs", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "e6707894-e4f7-47f8-b1c9-419cf457f00f", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "1eed0551-063b-467c-89df-47b3734c0853", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "2db310cc-0bc9-4ceb-8a19-6b1867c0713d", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "cb98bb8e-f30a-4709-a119-0f614843f3bd", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/PCF-10S-ClassroomSetup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "9cd189f8-f2ab-4d41-8c3c-88a7121a5e6f", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e8ddb0e4-9254-43ec-ad00-3ec55b795d0e", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Steps to complete<br>\nImplement the **`challenge()`** function to achieve the following:\n\n- Read Loan Requests from **`silverLoanRequestsPath`** into a DataFrame.\n- Create a function which extracts the currency string from **`request_amount`** and converts `$` to `USD`.\n- Register this function as a UDF and call it **`get_currency_udf`**.\n- Now that you implemented a UDF, let's see if we can achieve the same with built-in functions. Create a new DataFrame where you use the built-in functions for extracting both the **`currency`** and the **`amount`** from the **`request_amount`** column: call these new columns **`currency`** and **`amount`**.\n- Drop the **`request_amount`** column when you are done with the extractions.\n- Create a new DataFrame called **`finalOK`**, which contains those values where the **`missing_amount`** and the **`banned_investor`** columns are false.\n- Save finalOK as a Delta table to **`targetDirectory`**.\n- Create a new DataFrame called **`finalCheck`** containing those values where either the **`missing_amount`** or the **`banned_investor`** columns are true.\n- Save finalCheck as a Delta table to **`manualCheckPath`**.\n- Return the UDF, finalOK and finalCheck as an output of the function.\n\n<p> The resulting DataFrame's expected schema is:\n  \n|name|type|\n|---|---|\n|investor_id|LongType|\n|loan_id|LongType|\n|product_id|LongType|\n|request_length|LongType|\n|request_time|TimestampType|\n|valid_to|TimestampType|\n|password_hash|StringType|\n|missing_amount|BooleanType|\n|banned_investor|BooleanType|\n|loan_alert|StringType|\n|currency|StringType|\n|amount|IntegerType|", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "719bc060-302a-4a26-9d87-6ae415543334", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "cb5dfd9e-d3fb-4963-a9d7-816727dbaf51", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "# ANSWER\n\ndef solution(spark, silverLoanRequestsPath, manualCheckPath, targetDirectory):\n  from pyspark.sql.functions import col, regexp_extract, when\n  import re\n  \n  # Read Loan Requests from `silverLoanRequestsPath`.\n  res = spark.read.format(\"delta\").load(silverLoanRequestsPath)\n  \n  # Create a function, which extracts the currency string from `request_amount` and converts `$` to `USD`.\n  def get_currency(str):\n      if not str:\n         return \"\"\n      currencyStr = re.sub(\"[0-9 ]+\",\"\",str)\n      return currencyStr if currencyStr != \"$\" else \"USD\"\n\n  # Register this function as a UDF and call it `get_currency_udf`.\n  get_currency_udf = udf(get_currency)\n  \n  # Now that you implemented a UDF, let's see if we can achieve the \n  # same with built-in functions. Create a new DataFrame where you use \n  # the built-in functions for extracting both the `currency` and the `amount` from the `request_amount` column.\n  # Call these new columns `currency` and `amount`.\n  # Drop the `request_amount` column when you are done with the extractions.\n  raw_price_currency_col = regexp_extract(col(\"request_amount\"),\"^([^0-9 ]+)\", 0)\n  price_currency_col = when(raw_price_currency_col == \"$\", \"USD\").otherwise(raw_price_currency_col).alias(\"currency\")\n\n  price_amount_col = regexp_extract(col(\"request_amount\"),\"([0-9]+)$\", 0).cast(\"integer\").alias(\"amount\")\n  \n  finalDF = res.select(\"*\", price_currency_col, price_amount_col).drop(\"request_amount\")\n\n  # Create a new DataFrame called `finalOK`, which contains those values where the \n  # `missing_amount` and the `banned_investor` columns are false.\n  finalOK = finalDF.filter(col(\"missing_amount\") == False).filter(col(\"banned_investor\") == False)\n  \n  # Save finalOK as a Delta table to `targetDirectory`.\n  finalOK.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").save(targetDirectory) \n\n  # Create a new DataFrame called `finalCheck` containing those values\n  # where either the `missing_amount` or the `banned_investor` columns are true.\n  finalCheck = finalDF.filter((col(\"missing_amount\") == True) | (col(\"banned_investor\") == True))\n  \n  # Save finalCheck as a Delta table to `manualCheckPath` with overwrite mode and overwrite schema option.\n  finalCheck.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(manualCheckPath)\n  \n  # Return the UDF, finalOK and finalCheck in a tuple.\n  return (get_currency_udf, finalOK, finalCheck)\n  \n(get_currency_udf, finalOK, finalCheck) = solution(spark, silverLoanRequestsPath, manualCheckPath, targetDirectory)\nfinalOK.show(2)\nfinalCheck.show(2)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "ff7b2252-030d-4309-bbfb-380a9cc7d133", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "c03bee62-da3f-401c-86fc-efde04b860a3", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Reality Check</h2>\n\nRun the following cell to make sure you are on track:", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "252149d2-9f25-4fe2-819d-ea36ccd3f8eb", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "718bb3ae-2a74-425f-8738-0495b8b9a648", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "# ANSWER - Test your solution\nrealityCheck(solution, spark, silverLoanRequestsPath, manualCheckPath, targetDirectory)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "4c081135-14a9-4409-9108-fa1c701a28f1", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "90b2ccb0-8ad1-410b-a5fe-5075688dc3de", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "b0f00f8e-4bf6-4150-ae4a-522a9807f8f1", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "1bff7cc5-a0de-47c8-b591-101fc03cc69d", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 10, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/Classroom-Cleanup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "58b5c029-8901-4248-9c10-31d80acbc773", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "22f1ef5d-f0f0-42ba-aaf9-c195016d349e", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 11, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## <img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps\n\nStart the next challenge, [Stock Transactions]($./PCF 11S - Stock Transactions)\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "285b27c4-5654-43c6-b73b-1840f395f5b5", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "9caebb86-0df1-45e1-9378-4be0cad031cf", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 12, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "f774c541-3121-4bbc-b056-e9b61674a4e2", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "29f73a00-2859-406d-964b-b2f047ec7384", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 13, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "2230c81d-6536-4905-88e3-c51cbcf8e337", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "PCF 10S - Loan Requests 2", "origId": 0, "version": "NotebookV1"}