{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "479a1d53-25d7-452c-898e-24f7846e6f8a", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e06df0ee-ca3c-425c-867c-dbeff19d5236", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\n# Silver To Gold - Sales Orders Table\n\nWe want to pay close attention to cases where we mark loan requests green (good to go) but the recent spending balance of the investor is deep into negative territory. This is a gold notebook required by our analysts to support their decision making.\n\n## In this exercise you will:\n* Find out how to register DataFrames as Spark SQL Temporary Views\n* Learn how to work with SQL queries\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 7.0**", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "995c9676-faaf-4119-ae8c-26e0e6373bb4", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "f0764808-c11f-4d49-9956-e7eed18f7138", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<h2 style=\"color:red\">Instructor Note</h2>\n\n\n\nThings to talk about:\n- gold level tables in detail, including:\n  - their purpose:\n    - provide consumable data for dashboards, ml algorithms, analysts\n    - contain sanitized and obfuscated data to prevent privacy issues\n    - aggregate and select the required features only\n  - what they are and what they aren't:\n    - cleaned, filtered, aggregated, projected super focused tables containing only the required features\n    - not bronze tables, no sensitive information, no raw features\n    - not silver tables, no new feature created, just using the existing ones\n  - optionally questions if an operation is gold level or not:\n    - trade counts by stocks\n    - deduplicated order list with order details\n    - investor informations, including their order history\n    - monthly average order volume\n- talk about the goal: we want to examine the suspicious green flagged loan requests with interesting investor balance so we'll generate an aggregated gold table \n- talk about the SQL API and how can it be used, detailing:\n  - the different ways of registering the dataframes as tables\n  - how replacing interfere with other users' tables\n  - how can they save dataframes as tables, where would the data saved, how to change it, what happens if the table is dropped\n  - show them how to do the parts of the exercise using only SQL (like reading and registering tables without using the DF API)\n  - show them the %sql magic command", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "13ca4276-5858-4714-b41e-5f926607b656", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "bdd4d1a2-4517-4bc2-ab9b-70796d3f22de", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "7ddab36a-efbd-48e3-a5a7-4986b1837114", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "2a7fb3dd-0e88-4310-86a2-983bef3d8190", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/PCF-15G-ClassroomSetup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "3b3f5c14-0dc5-4298-8662-d021ff67428b", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "45b4f07a-8f8d-41fc-8646-8015108f7adf", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Steps to Complete<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.\n\n\nImplement the **`challenge()`** function to achieve the following:\n\n- Read Delta table from **`silverLoanRequestsPath`** to create the **`loanRequests`** DataFrame.\n- Read Delta table from **`silverStockOrdersPath`** to create the **`stockTransactions`** DataFrame.\n \n#### Use Spark SQL on the Temp Views to achieve the following:\n\n- Register the 2 tables as Spark SQL Temp Views, **`loans`** and **`stocks`** to create an SQL query.\n- Group the stocks table by **`investor`**, **`month`** and **`year`**, summing up the **`spend_balance`** column.\n- Inner join this grouped table with the **`loans`** table on **`investor`** and **`investor_id`** fields.\n- Only keep records where the **`loan_alert`** is green and **`stocks`** are from September 2019.\n- Select the columns to meet the expected schema described below.\n\n#### Use the DataFrame API to:\n\n- Print the schema.\n- Write the result to **`targetDirectory`** as a Delta table, using the overwrite mode.\n- Return the joined DataFrame.\n- Only select the columns listed below. The schema of the resulting DataFrame should look like this:\n\n|name|type|\n|---|---|\n|investor_id|LongType|\n|loan_alert|StringType|\n|amount|IntegerType|\n|total_spend_balance|DoubleType|", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "2c879840-9fe8-47e6-bd30-fd60f16d0142", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "14c28dd4-8520-477b-ba91-a8454baf4bcd", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER\n\ndef solution(spark:org.apache.spark.sql.SparkSession, silverLoanRequestsPath:String, silverStockOrdersPath:String, targetDirectory:String) : DataFrame = {\n  \n  //Read the Delta table from `silverLoanRequestsPath` to create the `loanRequests` DataFrame.\n  val loanRequests = (spark.read.format(\"delta\").load(silverLoanRequestsPath))\n\n  //Read the Delta table from `silverStockOrdersPath` to create the `stockTransactions` DataFrame.\n  val stockTransactions = (spark.read.format(\"delta\").load(silverStockOrdersPath))\n  \n  //Register the two tables as Spark SQL Temp Views, loans and stocks to write a SQL query.\n  loanRequests.createOrReplaceTempView(\"loans\")\n  stockTransactions.createOrReplaceTempView(\"stocks\")\n\n  // Group the stocks table by investor, month and year, summing up the spend_balance column.\n  // Inner join this grouped table with the loans table on investor and investor_id fields.\n  // Only keep records where the loan_alert is green and stocks are from September 2019.\n  // Select the columns to meet the expected schema described in Steps to Complete.\n  val gold = spark.sql(\"\"\"SELECT \n                    l.investor_id, l.loan_alert, \n                    l.amount, s.total_spend_balance\n                    FROM\n                    loans l\n                    JOIN (SELECT investor, SUM(spend_balance) total_spend_balance, month, year \n                          FROM stocks\n                          GROUP BY investor, year, month\n                          ) s \n                    ON(s.investor = l.investor_id)\n                    WHERE l.loan_alert = \"green\" AND\n                          s.month = \"9\" AND s.year = \"2019\"\n                    \"\"\")\n\n  \n  // Print the schema.\n  gold.printSchema()\n  \n  // Write the result to `targetDirectory` as a Delta table, using the overwrite mode.\n  gold.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").save(targetDirectory)\n  \n  // Return the joined DataFrame.\n  return gold\n}\n\nval finalDF = solution(spark, silverLoanRequestsPath, silverStockOrdersPath, targetDirectory)\ndisplay(finalDF)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "fb5fdb37-471a-40f4-9f72-4c0ed1d04814", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "1185fbec-ed62-4185-b26b-1eb962c4ebeb", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Reality Check</h2>\n\nRun the following cell to make sure you are on track:", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "208b5e1b-66c0-46c8-bdfe-67832bb1a508", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "faf64559-bf9f-4756-94ec-5333a6033786", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER - Test your solution\nrealityCheck(solution, spark, silverLoanRequestsPath, silverStockOrdersPath, targetDirectory)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "3d237601-7b40-4e62-842d-ce97b453212c", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "8e3eeccd-2899-44a1-b7d9-167ea1235dc4", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "26fe2f46-57bf-49dd-bcc6-ec3b62c1a20a", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "765883ba-10ce-4fd7-bbfc-74637f3f13df", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 10, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/Classroom-Cleanup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "7e71871d-fc99-43ad-8e49-2118e427fcb7", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "08c5931e-e9f7-47d0-a30d-e7bc7ed96421", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 11, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## <img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps\n\nStart the next challenge, [Price Over Time]($./PCF 16G - Price Over Time)\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "dece4f0a-1e22-4be5-a263-a6e52baf8ec0", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "59d2f38c-10ae-4955-ac57-905b1f6f0e78", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 12, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "0c6df4c6-9c9c-4aaf-b7ea-299458f45f31", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "7847e9f4-d5d2-4520-a55b-3ffe6ae39e87", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 13, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "08f86074-97a4-44b1-aab7-76e27419ab2b", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF 15G - Trades vs Loans", "origId": 0, "version": "NotebookV1"}