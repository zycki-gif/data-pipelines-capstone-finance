{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "8df61f39-9bce-485d-b212-d6b93fdb1dbd", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "5005b0d9-d9e8-4903-b695-2af1e7309269", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\n# Bronze To Silver - Trade Balances\n\nWhen investors buy stocks, their cash balance is reduced. When they sell, their cash balance increases. Fees apply too, in association with investors' subscription type. In this notebook we are going to compute these negative and positive impacts on their cash balances.\n\n## In this exercise you will:\n* Learn how to transform and join DataFrames on different columns\n* Find out how to select columns after a join from one side of the join\n* Find out how to calculate new values based on existing columns\n* Find out how to express conditions with `when` and `otherwise`\n* Practice writing a DataFrame to a silver Delta table\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 7.0**", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "24221a6b-4990-4aa5-8bea-2eee7c753f02", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "86ec3cc7-76a6-4a4d-8704-3a64ff5e76ff", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<h2 style=\"color:red\">Instructor Note</h2>\n\n\n\nThings to talk about:\n- talk about the goal:\n  - what are we building right now: further transform and merge previously created silver tables and generate new metrics\n  - why is it useful: typical workflow which generate final metrics for business\n- extracting columnar expressions to variables will help on code readability tremendously\n- when-otherwise functions", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "79ddf598-d457-4dd6-b179-336f82330ad9", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "8098ce03-bdb5-476e-854e-88097d06874c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "cf675f45-13cc-4fe6-8a63-52da42e848bf", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "f9224fe3-463a-44ac-99c5-10d441aaec25", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/PCF-12S-ClassroomSetup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "2cad1687-c3da-4efe-909e-a06bf94049d1", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "16ad12f4-b1ba-40af-a5a7-9ef2524e8e44", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Steps to complete<br>\nImplement the **`challenge()`** function to achieve the following:\n\n- Currently stock orders don't include fees. Fees are changing for each subscription type. Subscription types are registered in the Investors table. We are going to read from three paths to join them so as to compute the **`spend_balance`**:\n\n  * Read the cleaned Stock Orders silver table from **`silverStockOrdersPath`** into a DataFrame and drop the **`clicked_items`** column.\n  * Read the Investors silver table from **`silverInvestorsPath`** into a DataFrame and select only the **`investor_id`** and **`subscription_id`** fields.\n  * Read the fees data from **`feesPath`** into a DataFrame and filter for the records where the **`product_id`** equals zero.\n  \n- Join Stock Orders with Investors on **`investor`** and **`investor_id`** fields. Keep all fields from Stock Orders and only the **`subscription_id`** from Investors.\n- Join the previous DataFrame with fees on **`subscription_id`**. Keep all columns from the previous DataFrame and only the **`fees`** field from the fees.\n\n- After these joins we have information on how much fee applies for each transaction in Stock Orders.\n- Generate a new columns named **`spend_balance`** with these conditions:\n  * If the **`type`** value is \"BUY\", multiply **`volume`** and **`price`**, reduce the **`fee`** and convert the result to negative. Here is the formula:\n    - spend_balance = -1 x [ (volume x price) - fees ]\n  * If the condition is not met, then you should not make it negative:\n    - spend_balance =      [ (volume x price) - fees ]\n\n- Write the resulting DataFrame to **`targetDirectory`** as a Delta table using the overwrite option.\n- Return the resulting DataFrame.\n\nThe variables **`silverStockOrdersPath`**, **`silverInvestorsPath`**, **`feesPath`**  and **`targetDirectory`** have already been defined in your environment.\n\n<p> The resulting DataFrame schema should look like this:\n  \n|name|type|\n|---|---|\n|investor|LongType|\n|ordertime|LongType|\n|price|DoubleType|\n|ticker|StringType|\n|transaction_id|LongType|\n|type|StringType|\n|volume|LongType|\n|order_timestamp|TimestampType|\n|year|IntegerType|\n|month|IntegerType|\n|day|IntegerType|\n|dow|IntegerType|\n|subscription_id|LongType|\n|fees|IntegerType|\n|spend_balance|DoubleType|\n  ", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "b1a8aead-96a7-4389-a824-4fa44d07e8a3", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "65c700a4-242f-4848-82c5-0a114883a616", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER\n\ndef solution(spark:org.apache.spark.sql.SparkSession, silverStockOrdersPath:String, silverInvestorsPath:String, feesPath:String, targetDirectory:String) : DataFrame = {\n  import org.apache.spark.sql.functions._\n  import org.apache.spark.sql.types._\n  \n  //Read the cleaned Stock Orders silver table from **`silverStockOrdersPath`** into a DataFrame and drop the **`clicked_items`** column.\n  val stock_orders_cleaned = (spark.read.format(\"delta\").load(silverStockOrdersPath)\n                               .drop(\"clicked_items\")\n                              )\n\n  //Read the Investors silver table from **`silverInvestorsPath`** into a DataFrame and select only the **`investor_id`** and **`subscription_id`** fields.\n  val investors = (spark.read.format(\"delta\").load(silverInvestorsPath)\n                   .select(\"investor_id\", \"subscription_id\"))\n                            \n  //Read the fees data from **`feesPath`** into a DataFrame and filter for records where the **`product_id`** equals zero.\n  val fees = (spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"true\")\n          .csv(feesPath)\n          .filter(col(\"product_id\") === 0)\n         )\n  \n  //Join Stock Orders with Investors on the **`investor`** and the **`investor_id`** fields. \n  //Keep all fields from the Stock Orders and only the **`investor_id`** from Investors.\n  val res = (stock_orders_cleaned.as(\"st\")\n             .join(investors.as(\"in\"), $\"st.investor\" === $\"in.investor_id\", \"left\")\n             .select($\"st.*\", $\"in.subscription_id\")\n            )\n\n  //Join the previous DataFrame with fees on **`subscription_id`**. Keep all columns from the previous DataFrame and only the **`fees`** field from the fees.\n  val result = (res.join(fees, usingColumns=Seq(\"subscription_id\"), joinType=\"left\")\n               .select(res(\"*\"), fees(\"fees\"))\n               )\n  \n  //Generate a new column named **`spend_balance`** with the given conditions.\n  val df = (result.withColumn(\"spend_balance\", \n                     when(\n                       col(\"type\") === \"BUY\", (lit(-1) * col(\"volume\") * col(\"price\") - col(\"fees\")))\n                       .otherwise(col(\"volume\") * col(\"price\") - col(\"fees\")))                        \n           )\n  \n  //Write the resulting DataFrame to **`targetDirectory`** as a Delta table using the overwrite option.\n  df.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").save(targetDirectory)\n\n  //Return the resulting DataFrame.\n  return df\n}\n\nval solutionDF = solution(spark, silverStockOrdersPath, silverInvestorsPath, feesPath, targetDirectory)\ndisplay(solutionDF)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "ad39a4aa-e185-4786-bbe1-3b95bb31e186", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "7e2509f4-9d5f-4aae-9da9-628f00bbf050", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Reality Check</h2>\n\nRun the following cell to make sure you are on track:", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "0e20a488-34cc-4daf-a0b5-dd5b080f2dc1", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "7fa7bf08-0272-4c7b-bf6e-f34b16e50564", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER - Test your solution\nrealityCheck(solution, spark, silverStockOrdersPath, silverInvestorsPath, feesPath, targetDirectory)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "4e151fd0-a93d-4b02-91aa-489c98a20daf", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "54e8d82d-390d-4bcd-a48e-3bb24d942cc9", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "ac4dcd43-1499-4fb7-ae2d-b8fe97c8665d", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "16a4d7f7-8797-4991-add8-d3fbfac33766", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 10, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/Classroom-Cleanup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "debd5c8e-b153-42cc-b42f-d8be55512545", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "b800d207-f74d-496b-9c16-5e79d43995db", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 11, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## <img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps\n\nStart the next challenge, [Clicks]($./PCF 13S - Clicks)\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "c6264465-22a8-4de9-922b-0923b239b5c7", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "462e26c6-0be6-4dc7-949f-7512a9bc8c76", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 12, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "09104050-eb29-478d-b098-02d9018d15ab", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "22e9523e-b598-4576-a589-98bf1025bab1", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 13, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "6bc7eaf3-7b30-49dd-816f-adc768567290", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF 12S - Trade Balances", "origId": 0, "version": "NotebookV1"}