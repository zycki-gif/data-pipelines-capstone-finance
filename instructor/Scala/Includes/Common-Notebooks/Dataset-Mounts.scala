{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%scala\n// **********************************\n//  GET AZURE DATASOURCE\n// **********************************\n\ndef getAzureDataSource(): (String,String,String) = {\n  val datasource = spark.conf.get(\"com.databricks.training.azure.datasource\").split(\"\\t\")\n  val source = datasource(0)\n  val sasEntity = datasource(1)\n  val sasToken = datasource(2)\n  return (source, sasEntity, sasToken)\n}\n\n//**********************************\n// CREATE THE MOUNTS\n//**********************************\n\ndef getAwsRegion():String = {\n  try {\n    import scala.io.Source\n    import scala.util.parsing.json._\n\n    val jsonString = Source.fromURL(\"http://169.254.169.254/latest/dynamic/instance-identity/document\").mkString // reports ec2 info\n    val map = JSON.parseFull(jsonString).getOrElse(null).asInstanceOf[Map[Any,Any]]\n    map.getOrElse(\"region\", null).asInstanceOf[String]\n\n  } catch {\n    // We will use this later to know if we are Amazon vs Azure\n    case _: java.io.FileNotFoundException => null\n  }\n}\n\ndef getAzureRegion():String = {\n  import com.databricks.backend.common.util.Project\n  import com.databricks.conf.trusted.ProjectConf\n  import com.databricks.backend.daemon.driver.DriverConf\n\n  new DriverConf(ProjectConf.loadLocalConfig(Project.Driver)).region\n}\n\n// These keys are read-only so they're okay to have here\nval awsAccessKey = \"AKIAJBRYNXGHORDHZB4A\"\nval awsSecretKey = \"a0BzE1bSegfydr3%2FGE3LSPM6uIV5A4hOUfpH8aFF\"\nval awsAuth = s\"${awsAccessKey}:${awsSecretKey}\"\n\ndef getAwsMapping(region:String):(String,Map[String,String]) = {\n\n  val MAPPINGS = Map(\n    \"ap-northeast-1\" -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-ap-northeast-1/common\", Map[String,String]()),\n    \"ap-northeast-2\" -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-ap-northeast-2/common\", Map[String,String]()),\n    \"ap-south-1\"     -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-ap-south-1/common\", Map[String,String]()),\n    \"ap-southeast-1\" -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-ap-southeast-1/common\", Map[String,String]()),\n    \"ap-southeast-2\" -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-ap-southeast-2/common\", Map[String,String]()),\n    \"ca-central-1\"   -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-ca-central-1/common\", Map[String,String]()),\n    \"eu-central-1\"   -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-eu-central-1/common\", Map[String,String]()),\n    \"eu-west-1\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-eu-west-1/common\", Map[String,String]()),\n    \"eu-west-2\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-eu-west-2/common\", Map[String,String]()),\n\n    // eu-west-3 in Paris isn't supported by Databricks yet - not supported by the current version of the AWS library\n    // \"eu-west-3\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-eu-west-3/common\", Map[String,String]()),\n    \n    // Use Frankfurt in EU-Central-1 instead\n    \"eu-west-3\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-eu-central-1/common\", Map[String,String]()),\n    \n    \"sa-east-1\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-sa-east-1/common\", Map[String,String]()),\n    \"us-east-1\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-us-east-1/common\", Map[String,String]()),\n    \"us-east-2\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training-us-east-2/common\", Map[String,String]()),\n    \"us-west-2\"      -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training/common\", Map[String,String]()),\n    \"_default\"       -> (s\"s3a://${awsAccessKey}:${awsSecretKey}@databricks-corp-training/common\", Map[String,String]())\n  )\n\n  MAPPINGS.getOrElse(region, MAPPINGS(\"_default\"))\n}\n\ndef getAzureMapping(region:String):(String,Map[String,String]) = {\n\n  var MAPPINGS = Map(\n    \"australiacentral\"    -> (\"dbtrainaustraliasoutheas\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=br8%2B5q2ZI9osspeuPtd3haaXngnuWPnZaHKFoLmr370%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"australiacentral2\"   -> (\"dbtrainaustraliasoutheas\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=br8%2B5q2ZI9osspeuPtd3haaXngnuWPnZaHKFoLmr370%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"australiaeast\"       -> (\"dbtrainaustraliaeast\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=FM6dy59nmw3f4cfN%2BvB1cJXVIVz5069zHmrda5gZGtU%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"australiasoutheast\"  -> (\"dbtrainaustraliasoutheas\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=br8%2B5q2ZI9osspeuPtd3haaXngnuWPnZaHKFoLmr370%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"canadacentral\"       -> (\"dbtraincanadacentral\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=dwAT0CusWjvkzcKIukVnmFPTmi4JKlHuGh9GEx3OmXI%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"canadaeast\"          -> (\"dbtraincanadaeast\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=SYmfKBkbjX7uNDnbSNZzxeoj%2B47PPa8rnxIuPjxbmgk%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"centralindia\"        -> (\"dbtraincentralindia\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=afrYm3P5%2BB4gMg%2BKeNZf9uvUQ8Apc3T%2Bi91fo/WOZ7E%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"centralus\"           -> (\"dbtraincentralus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=As9fvIlVMohuIV8BjlBVAKPv3C/xzMRYR1JAOB%2Bbq%2BQ%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"eastasia\"            -> (\"dbtraineastasia\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=sK7g5pki8bE88gEEsrh02VGnm9UDlm55zTfjZ5YXVMc%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"eastus\"              -> (\"dbtraineastus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=tlw5PMp1DMeyyBGTgZwTbA0IJjEm83TcCAu08jCnZUo%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"eastus2\"             -> (\"dbtraineastus2\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=Y6nGRjkVj6DnX5xWfevI6%2BUtt9dH/tKPNYxk3CNCb5A%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"japaneast\"           -> (\"dbtrainjapaneast\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=q6r9MS/PC9KLZ3SMFVYO94%2BfM5lDbAyVsIsbBKEnW6Y%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"japanwest\"           -> (\"dbtrainjapanwest\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=M7ic7/jOsg/oiaXfo8301Q3pt9OyTMYLO8wZ4q8bko8%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"northcentralus\"      -> (\"dbtrainnorthcentralus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=GTLU0g3pajgz4dpGUhOpJHBk3CcbCMkKT8wxlhLDFf8%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"northcentralus\"      -> (\"dbtrainnorthcentralus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=GTLU0g3pajgz4dpGUhOpJHBk3CcbCMkKT8wxlhLDFf8%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"northeurope\"         -> (\"dbtrainnortheurope\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=35yfsQBGeddr%2BcruYlQfSasXdGqJT3KrjiirN/a3dM8%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"southcentralus\"      -> (\"dbtrainsouthcentralus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=3cnVg/lzWMx5XGz%2BU4wwUqYHU5abJdmfMdWUh874Grc%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"southcentralus\"      -> (\"dbtrainsouthcentralus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=3cnVg/lzWMx5XGz%2BU4wwUqYHU5abJdmfMdWUh874Grc%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"southindia\"          -> (\"dbtrainsouthindia\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=0X0Ha9nFBq8qkXEO0%2BXd%2B2IwPpCGZrS97U4NrYctEC4%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"southeastasia\"       -> (\"dbtrainsoutheastasia\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=H7Dxi1yqU776htlJHbXd9pdnI35NrFFsPVA50yRC9U0%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"uksouth\"             -> (\"dbtrainuksouth\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=SPAI6IZXmm%2By/WMSiiFVxp1nJWzKjbBxNc5JHUz1d1g%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"ukwest\"              -> (\"dbtrainukwest\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=olF4rjQ7V41NqWRoK36jZUqzDBz3EsyC6Zgw0QWo0A8%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"westcentralus\"       -> (\"dbtrainwestcentralus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=UP0uTNZKMCG17IJgJURmL9Fttj2ujegj%2BrFN%2B0OszUE%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"westeurope\"          -> (\"dbtrainwesteurope\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=csG7jGsNFTwCArDlsaEcU4ZUJFNLgr//VZl%2BhdSgEuU%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"westindia\"           -> (\"dbtrainwestindia\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=fI6PNZ7YvDGKjArs1Et2rAM2zgg6r/bsKEjnzQxgGfA%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"westus\"              -> (\"dbtrainwestus\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=%2B1XZDXbZqnL8tOVsmRtWTH/vbDAKzih5ThvFSZMa3Tc%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"westus2\"             -> (\"dbtrainwestus2\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=DD%2BO%2BeIZ35MO8fnh/fk4aqwbne3MAJ9xh9aCIU/HiD4%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\"),\n    \"_default\"            -> (\"dbtrainwestus2\",\n                              \"?ss=b&sp=rl&sv=2018-03-28&st=2018-04-01T00%3A00%3A00Z&sig=DD%2BO%2BeIZ35MO8fnh/fk4aqwbne3MAJ9xh9aCIU/HiD4%3D&srt=sco&se=2023-04-01T00%3A00%3A00Z\")\n  )\n\n  val (account: String, sasKey: String) = MAPPINGS.getOrElse(region, MAPPINGS(\"_default\"))\n\n  val blob = \"training\"\n  val source = s\"wasbs://$blob@$account.blob.core.windows.net/\"\n  val configMap = Map(\n    s\"fs.azure.sas.$blob.$account.blob.core.windows.net\" -> sasKey\n  )\n\n  (source, configMap)\n}\n\ndef mountFailed(msg:String): Unit = {\n  println(msg)\n}\n\ndef retryMount(source: String, mountPoint: String): Unit = {\n  try { \n    // Mount with IAM roles instead of keys for PVC\n    dbutils.fs.mount(source, mountPoint)\n  } catch {\n    case e: Exception => mountFailed(s\"*** ERROR: Unable to mount $mountPoint: ${e.getMessage}\")\n  }\n}\n\ndef mount(source: String, extraConfigs:Map[String,String], mountPoint: String): Unit = {\n  try {\n    dbutils.fs.mount(source, mountPoint, extraConfigs=extraConfigs)\n  } catch {\n    case ioe: java.lang.IllegalArgumentException => retryMount(source, mountPoint)\n    case e: Exception => mountFailed(s\"*** ERROR: Unable to mount $mountPoint: ${e.getMessage}\")\n  }\n}\n\ndef autoMount(fix:Boolean = false, failFast:Boolean = false, mountDir:String = \"/mnt/training\"): Unit = {\n  var awsRegion = getAwsRegion()\n\n  val (source, extraConfigs) = if (awsRegion != null)  {\n    spark.conf.set(\"com.databricks.training.region.name\", awsRegion)\n    getAwsMapping(awsRegion)\n\n  } else {\n    val azureRegion = getAzureRegion()\n    spark.conf.set(\"com.databricks.training.region.name\", azureRegion)\n    initAzureDataSource(azureRegion)\n  }\n  \n  val resultMsg = mountSource(fix, failFast, mountDir, source, extraConfigs)\n  displayHTML(s\"Mounting course-specific datasets to <b>$mountDir</b>...</br>\"+resultMsg)\n}\n\ndef initAzureDataSource(azureRegion:String):(String,Map[String,String]) = {\n  val mapping = getAzureMapping(azureRegion)\n  val (source, config) = mapping\n  val (sasEntity, sasToken) = config.head\n\n  val datasource = \"%s\\t%s\\t%s\".format(source, sasEntity, sasToken)\n  spark.conf.set(\"com.databricks.training.azure.datasource\", datasource)\n\n  return mapping\n}\n\ndef mountSource(fix:Boolean, failFast:Boolean, mountDir:String, source:String, extraConfigs:Map[String,String]): String = {\n  val mntSource = source.replace(awsAuth+\"@\", \"\")\n\n  if (dbutils.fs.mounts().map(_.mountPoint).contains(mountDir)) {\n    val mount = dbutils.fs.mounts().filter(_.mountPoint == mountDir).head\n    if (mount.source == mntSource) {\n      return s\"\"\"Datasets are already mounted to <b>$mountDir</b> from <b>$mntSource</b>\"\"\"\n      \n    } else if (failFast) {\n      throw new IllegalStateException(s\"Expected $mntSource but found ${mount.source}\")\n      \n    } else if (fix) {\n      println(s\"Unmounting existing datasets ($mountDir from $mntSource)\")\n      dbutils.fs.unmount(mountDir)\n      mountSource(fix, failFast, mountDir, source, extraConfigs)\n\n    } else {\n      return s\"\"\"<b style=\"color:red\">Invalid Mounts!</b></br>\n                      <ul>\n                      <li>The training datasets you are using are from an unexpected source</li>\n                      <li>Expected <b>$mntSource</b> but found <b>${mount.source}</b></li>\n                      <li>Failure to address this issue may result in significant performance degradation. To address this issue:</li>\n                      <ol>\n                        <li>Insert a new cell after this one</li>\n                        <li>In that new cell, run the command <code style=\"color:blue; font-weight:bold\">%scala fixMounts()</code></li>\n                        <li>Verify that the problem has been resolved.</li>\n                      </ol>\"\"\"\n    }\n  } else {\n    println(s\"\"\"Mounting datasets to $mountDir from $mntSource\"\"\")\n    mount(source, extraConfigs, mountDir)\n    return s\"\"\"Mounted datasets to <b>$mountDir</b> from <b>$mntSource<b>\"\"\"\n  }\n}\n\ndef fixMounts(): Unit = {\n  autoMount(true)\n}\n\nautoMount(true)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "cead3e8b-5b03-407d-a5c2-035420bd63db", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e7e1aa28-e7a7-41a7-bed5-a199a75d3000", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%python\n\n#**********************************\n# GET AZURE DATASOURCE\n#**********************************\n\n\ndef getAzureDataSource(): \n  datasource = spark.conf.get(\"com.databricks.training.azure.datasource\").split(\"\\t\")\n  source = datasource[0]\n  sasEntity = datasource[1]\n  sasToken = datasource[2]\n  return (source, sasEntity, sasToken)\n\n\nNone # Suppress output\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "1f5fd66d-b6f9-4c58-b4b1-6910df1238de", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "1d66f3e3-1c66-4660-ab77-a201bdf4924f", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "2e7f26ff-5c0c-4019-91dd-c58b47f274b0", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "Dataset-Mounts", "origId": 0, "version": "NotebookV1"}