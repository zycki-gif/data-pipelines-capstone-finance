{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%run ./Classroom-Setup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "db3dc656-9aed-4655-b1c7-93f12325994b", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "df46b31e-7b5b-4f68-a5fa-43ab9f787a2f", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n// This cell comes before `Classroom Setup` so this notebook fails fast if the students failed to install the org.hsqldb:hsqldb:2.5.0 library.\n\ntry {\n  Class.forName(\"org.hsqldb.jdbc.JDBCDriver\")\n} catch {\n  case e: ClassNotFoundException =>\n    throw new java.sql.SQLException(\"Please install the HyperSQL library: org.hsqldb:hsqldb:2.5.0\").initCause(e)\n}\n\n/* dbutils.meta.define allows us to define a singleton inside a package then call displayHTML to suppress any output messages. */\ndbutils.meta.define(\"com.databricks.training\", \"\"\"\n  /**\n   Defines a HyperSQL database for use in training.  This wrapper ensures only one copy is running at any given time.\n  */\n  object ClassroomDB {\n    import org.hsqldb.server.Server\n    import org.hsqldb.persist.HsqlProperties\n    import org.apache.spark.sql.SparkSession\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.ResultSet;\n    import java.sql.Statement;\n\n    private var server : Server = null\n\n    private val serverProperties = new HsqlProperties();\n    {\n      serverProperties.setProperty(\"server.daemon\", \"true\")\n      serverProperties.setProperty(\"server.no_system_exit\", \"true\")\n      serverProperties.setProperty(\"server.remote_open\", \"false\")\n      serverProperties.setProperty(\"server.dbname.0\", \"classroom\")\n      serverProperties.setProperty(\"server.database.0\", \"mem\")\n      // serverProperties.setProperty(\"sql.syntax_mys\", \"true\") // NOT WORKING, SEE EXPLICIT QUERY FIX BELOW\n    }\n\n    val dbProps = new java.util.Properties()\n    dbProps.setProperty(\"driver\", \"org.hsqldb.jdbc.JDBCDriver\");\n    dbProps.setProperty(\"user\", \"SA\");\n    dbProps.setProperty(\"password\", \"\");\n\n    def jdbcURL(implicit spark : SparkSession) = {\n      val dbHostName = spark.conf.get(\"spark.driver.host\")\n      s\"jdbc:hsqldb:hsql://${dbHostName}/classroom\"\n    }\n\n    /** Starts database only if it's not already running. */\n    def start() : Unit = {\n      this.synchronized {\n        if (this.server != null && !this.server.isNotRunning)\n          return\n        this.server = new Server()\n        this.server.setProperties(serverProperties)\n        this.server.setErrWriter(null)\n        this.server.setLogWriter(null)\n        this.server.start()\n      }\n    }\n\n    def stop() : Unit = {\n      this.synchronized {\n        if (this.server != null && !server.isNotRunning)\n          this.server.shutdown\n        this.server = null\n      }\n    }\n    \n    /** Restarts database into a clean state, even if it is already running. */\n    def restart() : Unit = {\n      this.synchronized {\n        this.stop()\n        this.start()\n      }\n    }\n  }\n\"\"\")\n\ndisplayHTML(s\"Loaded database library.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "4e0a08b7-c0e5-4e8b-8a7b-d976325b0950", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "29060145-1e1e-40c1-80a6-050a4ee78e29", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\ncom.databricks.training.ClassroomDB.restart()\ndisplayHTML(s\"Started database.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "ef793b27-e26b-4d05-861d-28b90920890e", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "4136a519-b7eb-4dbf-998f-995924eaa485", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n\ndef setMySQLCompatibility = {\n  import java.sql.DriverManager\n\n  val connProps = com.databricks.training.ClassroomDB.dbProps\n  val con = DriverManager.getConnection(\n    com.databricks.training.ClassroomDB.jdbcURL(spark),\n    connProps.get(\"user\").toString,\n    connProps.get(\"password\").toString)\n  val stmt = con.createStatement()\n  val result = stmt.executeQuery(\"SET DATABASE SQL SYNTAX MYS TRUE\")\n}\n\nsetMySQLCompatibility\ndisplayHTML(\"Set MySQL Compatibility Mode.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "c108e612-7092-4eff-a528-13f6b5cb85a3", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "999afca3-f57b-40f2-89a1-2618deb92dd8", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%python\n\ninvestorsPath = financeDataPath + \"/investors/investors.parquet\"\ninvestors_raw = spark.read.option(\"inferSchema\", \"True\").option(\"header\",\"True\").parquet(investorsPath)\n\ntableName = \"investors\"\njdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ninvestors_raw.write.mode(\"overwrite\").jdbc(jdbcURL, tableName, properties=dbProps)\ndisplayHTML(\"Investors table created.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "20a90f6b-e14f-4766-a8f1-4182ca5796ac", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e178eb43-41f5-4813-a287-9c08929a2457", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "val targetDirectory = workingDir + \"/investors.delta\"\ncourseAdvertisements(\"targetDirectory\") = (\"v\", targetDirectory , targetDirectory)\nallDone(courseAdvertisements)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "c3c15106-e796-4258-a637-333018d80dae", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d1d6cbe0-2260-4905-9709-e0aa9ad7691c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// SETUP\nimport org.apache.spark.sql.SparkSession\ndef realityCheck(testMethod:(SparkSession, String) => DataFrame, spark:SparkSession, targetDirectory:String): Unit = {\n  import org.apache.spark.sql.functions._\n  import org.apache.spark.sql.types._\n  import java.io.ByteArrayOutputStream\n  \n  val resultDF = testMethod(spark, targetDirectory)\n  \n  val jdbcURL = com.databricks.training.ClassroomDB.jdbcURL(spark)\n  val dbProps = com.databricks.training.ClassroomDB.dbProps\n  val correctDF = spark.read.jdbc(\n      url=jdbcURL,                  // the JDBC URL\n      table=\"investors\",            // the name of the table\n      properties=dbProps)           // the connection properties\n \n  def read_delta() : DataFrame = {\n      try {\n        spark.read.format(\"delta\").load(targetDirectory)\n      } catch { \n        case _: Throwable => spark.emptyDataFrame \n      }\n  }\n  \n  val resultOutput = new ByteArrayOutputStream\n  val correctOutput = new ByteArrayOutputStream\n\n  Console.withOut(resultOutput) {testMethod(spark, targetDirectory)}\n  Console.withOut(correctOutput) {correctDF.show(10, truncate=false)}\n  \n  val deltaTable = read_delta()\n  \n  val tests = new TestSuite()\n    tests.addTest(TestCase(id=\"PCF-03B-A\", description=\"Returns correct schema\",\n             testFunction = () => compareSchemas(resultDF.schema, correctDF.schema, testColumnOrder=false, testNullable=false)))\n    tests.addTest(TestCase(id=\"PCF-03B-B\", description=\"Returns DataFrame with correct number of rows\",     \n             testFunction = () => resultDF.count == correctDF.count))\n    tests.addTest(TestCase(id=\"PCF-03B-C\", description=\"Returns DataFrame with correct results\", \n             testFunction = () => compareDataFramesLimited(resultDF, correctDF)))\n    tests.addTest(TestCase(id=\"PCF-03B-D\", description=\"Prints expected output\", \n             testFunction = () => resultOutput.toString contains correctOutput.toString))\n    tests.addTest(TestCase(id=\"PCF-03B-E\", description = \"Delta table in place\",\n             testFunction = () => !deltaTable.isEmpty))\n    tests.addTest(TestCase(id=\"PCF-03B-F\", description = \"Delta table has correct content\",\n             testFunction = () => compareDataFramesLimited(deltaTable, correctDF)))\n  \n   \n  tests.displayResults()\n  \n}\n\ndisplayHTML(\"\"\"\nDeclared the following function:\n  <li><span style=\"color:green; font-weight:bold\">realityCheck</span></li>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "f10bfc63-478e-4cb0-9adc-b1e53072d13f", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e14022c8-ab0c-4d64-8af0-496c62ef93c6", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "val jdbcURL = com.databricks.training.ClassroomDB.jdbcURL(spark)\nval dbProps = com.databricks.training.ClassroomDB.dbProps\n\ndisplayHTML(s\"\"\"\n<h3>JDBC Connection Properties:</h3>\n<pre>\n  JDBC URL = ${jdbcURL}\n  Connection Properties: = ${dbProps}\n</pre>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "080ff8a8-bc57-4bee-bfbb-9180702bca53", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "03c03eb3-1e9b-4f45-bde2-ae1b0d4927e5", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "displayHTML(\"All done!\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "750e24aa-8cb5-469f-87b6-bb7d29f835c2", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "8dbd3b1b-8694-492e-9c5f-acfa21de4e6c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "c989dd9b-34b4-47ad-b84b-3acdce2789b1", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF-03B-ClassroomSetup", "origId": 0, "version": "NotebookV1"}