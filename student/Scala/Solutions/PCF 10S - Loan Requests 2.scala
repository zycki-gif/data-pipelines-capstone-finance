{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "45018bb9-2a0c-4fc3-82ad-ffa6ff4e42de", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "bcddb8b0-927a-4711-b65c-5449cedc7611", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\n# Bronze To Silver - Loan Requests 2\n\nLet's standardize the **`request_amount`** format in Purchase Orders and write two DataFrames to two different paths: one for loan requests without any problems and another for loan requests with missing amounts or blacklisted inverstors in need of manual checks  executed by our staff.\n\n\n## In this exercise you will:\n* Learn about User Defined Functions (UDFs)\n* Practice using performant built-in functions\n* Practice using filters with OR predicate\n* Practice using regular expressions \n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 7.0**", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "48408416-2e1a-4aec-8f9b-c80b5d3d1fb8", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "3cb2b9f7-6173-4347-bd33-667dd1df2d70", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "e9ba2b2e-2791-4f59-ac73-f5224e341bd2", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d3f7ad04-1b22-4f39-b700-c6b41e504525", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/PCF-10S-ClassroomSetup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "a1b7f888-4f82-42dc-beba-b1055577776b", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "fdf4fe54-873b-48a8-b38c-8d6a67be2ac4", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Steps to complete<br>\nImplement the **`challenge()`** function to achieve the following:\n\n- Read Loan Requests from **`silverLoanRequestsPath`** into a DataFrame.\n- Create a function which extracts the currency string from **`request_amount`** and converts `$` to `USD`.\n- Register this function as a UDF and call it **`get_currency_udf`**.\n- Now that you implemented a UDF, let's see if we can achieve the same with built-in functions. Create a new DataFrame where you use the built-in functions for extracting both the **`currency`** and the **`amount`** from the **`request_amount`** column: call these new columns **`currency`** and **`amount`**.\n- Drop the **`request_amount`** column when you are done with the extractions.\n- Create a new DataFrame called **`finalOK`**, which contains those values where the **`missing_amount`** and the **`banned_investor`** columns are false.\n- Save finalOK as a Delta table to **`targetDirectory`**.\n- Create a new DataFrame called **`finalCheck`** containing those values where either the **`missing_amount`** or the **`banned_investor`** columns are true.\n- Save finalCheck as a Delta table to **`manualCheckPath`**.\n- Return the UDF, finalOK and finalCheck as an output of the function.\n\n<p> The resulting DataFrame's expected schema is:\n  \n|name|type|\n|---|---|\n|investor_id|LongType|\n|loan_id|LongType|\n|product_id|LongType|\n|request_length|LongType|\n|request_time|TimestampType|\n|valid_to|TimestampType|\n|password_hash|StringType|\n|missing_amount|BooleanType|\n|banned_investor|BooleanType|\n|loan_alert|StringType|\n|currency|StringType|\n|amount|IntegerType|", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "89d32074-889f-4a6d-b2cb-4523cbdf2fce", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "3f3081e3-1db1-4f32-b2fb-fefbe58c695b", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER\n\ndef solution(spark:org.apache.spark.sql.SparkSession, silverLoanRequestsPath:String, manualCheckPath:String, targetDirectory:String) : (org.apache.spark.sql.expressions.UserDefinedFunction, DataFrame, DataFrame) = {\n  import org.apache.spark.sql.functions._\n  \n  // Read the Purchase Orders from `silverLoanRequestsPath`.\n  val res = spark.read.format(\"delta\").load(silverLoanRequestsPath)\n\n  // Create a function, which extracts the currency string from `request_amount` and converts `$` to `USD`.\n  // Register this function as a UDF and call it `get_currency_udf`.\n  val getCurrencyUdf = udf((str:String) => {\n      str match {\n          case null => \"\"\n          case _ => { \n            val currencyStr = str.replaceAll(\"[0-9 ]+\",\"\")\n            currencyStr match {\n              case \"$\" => \"USD\"\n              case _ => currencyStr\n            }\n          }\n      }\n  })\n  \n  // Now that you implemented a UDF, let's see if we can achieve the \n  // same with built-in functions. Create a new DataFrame where you use \n  // the built-in functions for extracting both the `currency` and the `request_amount`.\n  // Call these new columns `raw_price_currency_col` and `price_currency_col`.\n  // Drop the `currency` column when you are done with the extractions.\n  val raw_price_currency_col = regexp_extract(col(\"request_amount\"),\"^([^0-9 ]+)\", 0)\n  val price_currency_col = when(raw_price_currency_col === \"$\", \"USD\").otherwise(raw_price_currency_col).alias(\"currency\")\n  \n  val price_amount_col = regexp_extract(col(\"request_amount\"),\"([0-9]+)$\", 0).cast(\"integer\").alias(\"amount\")\n\n  val finalDF = res.select(col(\"*\"), price_currency_col, price_amount_col).drop(\"request_amount\")\n  \n  // Create a new DataFrame called `finalOK`, which contains those values\n  // where neither the `missing_amount` nor the `banned_investor` columns are true.\n  val finalOK = finalDF.filter(col(\"missing_amount\") === false).filter(col(\"banned_investor\") === false)\n  \n  // Save finalOK as a Delta table to `targetDirectory`.\n  finalOK.write.format(\"delta\").mode(\"overwrite\").save(targetDirectory)\n  \n  // Create a new DataFrame called `finalCheck` containing those values\n  // where either the `missing_amount` or the `banned_investor` columns are true.\n  val finalCheck = finalDF.filter((col(\"missing_amount\") === true) || (col(\"banned_investor\") === true))\n  \n  // Save finalCheck as a Delta table to `manualCheckPath` with overwrite mode and overwrite schema option.\n  finalCheck.write.format(\"delta\").mode(\"overwrite\").save(manualCheckPath)\n\n  // Return the UDF, finalOK and finalCheck in a tuple.\n  return (getCurrencyUdf, finalOK, finalCheck)\n}\n\nval (curr_udf, finalOK, finalCheck) = solution(spark, silverLoanRequestsPath, manualCheckPath, targetDirectory)\n\nfinalOK.show(2)\nfinalCheck.show(2)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "36b42299-3f3a-44c9-b2e8-b1491f7b0178", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e3e77433-6c92-4941-9288-f1af88a31050", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Reality Check</h2>\n\nRun the following cell to make sure you are on track:", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "326bce45-dc51-478f-9603-89ddb6117880", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "cb7280ce-76ee-4403-ad82-24402dac3742", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER - Test your solution\nrealityCheck(solution, spark, silverLoanRequestsPath, manualCheckPath, targetDirectory)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "bacd168e-6ab7-4c58-b56d-8e06cabf34fb", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "6b89bc64-dde4-4671-bf3f-1acd4546baa2", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "1b91b3c0-dfcc-4456-97c7-031649ee1203", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "bcf930af-cc9c-43aa-95fd-d4880b068cdc", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/Classroom-Cleanup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "b075cda5-e017-4fda-aeee-1ecbc63cce28", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "59c9f127-6c19-46b1-96b4-c28566a2ee96", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 10, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## <img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps\n\nStart the next challenge, [Stock Transactions]($./PCF 11S - Stock Transactions)\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "58993071-8980-4453-a40c-9d2e44721df4", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "8892bf17-1882-44b2-b036-91b6da60d211", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 11, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "4f6bf06b-6e53-450a-bc37-ebcbb82532e0", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "7e08e9f6-f369-48f9-8cf4-2923c14b21f1", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 12, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "87d6f7d5-e558-4665-bccc-6f8e9e84c8a5", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF 10S - Loan Requests 2", "origId": 0, "version": "NotebookV1"}