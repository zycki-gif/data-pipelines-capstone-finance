{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "cc1e68c8-be14-491f-a963-2e75d027727d", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "0b8892c6-bb62-4238-9af8-c733f620ac05", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\nWe are going to update our investors' credit scores by using the latest macroeconomic data received from the central bank.\n\n# Bronze To Silver - Investors\n\n## In this exercise you will:\n* Find out how to read from the bronze layer \n* Learn to create and rename columns\n* Practice using the `Row` object to compute with values on the Driver\n* Practice using `when` and `otherwise` to express conditions with Spark\n* Combine data available in a DataFrame and on the Driver with `lit`\n* Get familiar with writing out to Delta format\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 7.0**", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "cfc2d42b-9cf6-4194-bfef-dee9fa79679a", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "f7067031-18ee-4192-803d-632bfab0092f", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "76c8c2e3-9740-4db1-ab4b-5cd050a2e585", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "a8148731-c506-4d15-b2d1-c0fcd0556d16", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/PCF-07S-ClassroomSetup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "bcabf8ae-4ec1-4a49-a73e-eda356a648c8", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "c2a27609-1ce7-4e61-ad28-7d07ab716023", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Steps to complete<br>\nImplement the **`challenge()`** function to achieve the following:\n- Read the macroeconomic data from **`macroDataPath`** into a DataFrame. \n- The source contains all historical macroeconomic data. However, we only need the row with the latest date.\n- Collect the row with the latest date to the driver and assign it to a variable.\n- Compute the metric using the elements of this row. Here is the formula for the metric:\n  * The formula will multiply several columns and divide them by the country's GDP.\n  * metric = (fedfunds X dexuseu X unrate X dgs10 X a191rl1q225sbea X indpro X bamlh0a0hym2) / \"gdp\"\n- Now we are ready to bring in the Investors. Read the **`investorsPath`** into a DataFrame.\n- We only need the  **`investor_id`**, **`name`**, **`education`**, **`credit_score`**, **`subscription_id`**, **`risk_score`** and **`fav_stocks`** fields from Investors.\n- Update the **`credit_score`** column by adding the metric you computed. E.g., if an investor's credit score is 3 and the metric is 0.2, the new credit score will be 3.2.\n- There is a condition for updated credit scores: they must be between 0 and 10. Make sure that they don't exceed 10 or go below 0. In case it's above 10, set the value to 10. In case it's below 0, set the value to 0.\n- Write the result to **`targetDirectory`** as a Delta table, using the overwrite mode and overwrite schema method.\n- Return the resulting DataFrame.\n\n<p> **`macroDataPath`**, **`investorsPath`** and **`targetDirectory`** are already defined in your environment.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "eafed078-6274-4f45-9f50-63c19e0a1253", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "631dfab9-55ca-40f4-9e3a-f2ae086106f7", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER\n\ndef solution(spark:org.apache.spark.sql.SparkSession, macroDataPath:String, investorsPath:String, targetDirectory:String) : DataFrame = {\n  import org.apache.spark.sql.functions._\n  \n  // Read the macroeconomic data from `macroDataPath`.\n  val macro_2 = (spark.read.format(\"delta\").load(macroDataPath))\n  \n  // Collect the row with the latest date and assign it to a variable.\n  val maxDate = macro_2.select(max(col(\"date\"))).collect()\n  val macroRow = (macro_2\n               .filter(col(\"date\") === maxDate(0)(0))\n                   .select(\"fedfunds\", \"dexuseu\", \"unrate\", \"dgs10\", \"a191rl1q225sbea\", \"indpro\", \"bamlh0a0hym2\", \"gdp\")\n              ).collect()(0)\n\n  // Compute the metric using the elements of the row above, using the formula below:\n  //\u00a0metric = (fedfunds X dexuseu X unrate X dgs10 X a191rl1q225sbea X indpro X bamlh0a0hym2) / gdp\n  val metric = (macroRow.getDouble(0) * macroRow.getFloat(1) * macroRow.getFloat(2) * macroRow.getFloat(3) * macroRow.getFloat(4) * macroRow.getFloat(5) * macroRow.getFloat(6)\n            /  macroRow.getFloat(7))\n\n  // Read Investors from the `investorsPath`. \n\n  // We only need the `investor_id`, `name`, `education`, `credit_score`, `subscription_id`, `risk_score` and `fav_stocks` fields from Investors.\n  // Update the `credit_score` column by adding the metric you computed previously.\n  // Fix credit scores: they must be between 0 and 10. Make sure that they don't exceed 10 or go below 0. In case it's above 10, set the value to 10. In case it's below 0, set the value to 0.\n  val solution = (spark.read.format(\"delta\").load(investorsPath)\n                .select(\"investor_id\", \"name\", \"education\", \"credit_score\", \"subscription_id\", \"risk_score\", \"fav_stocks\")\n                .withColumn(\"credit_score\", (col(\"credit_score\") + lit(metric)))\n                .withColumn(\"credit_score\", when(col(\"credit_score\") > 10, lit(10)).otherwise(col(\"credit_score\")))\n                .withColumn(\"credit_score\", when(col(\"credit_score\") < 0, lit(0)).otherwise(col(\"credit_score\")))\n                )\n\n  // Write the result to targetDirectory as a Delta table, using the overwrite mode and overwrite schema method.\n  solution.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").save(targetDirectory)\n  \n  // Return the resulting DataFrame.\n  return solution\n\n}\n\nval solutionDF = solution(spark, macroDataPath, investorsPath, targetDirectory)\ndisplay(solutionDF)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "9270cf27-68cb-4b4c-b341-d1c80f94aadb", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d5807de6-0d28-4afd-b94a-c591289f71da", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Reality Check</h2>\n\nRun the following cell to make sure you are on track:", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "18db4222-f0eb-4e2b-8c27-cc5e8b6815e8", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "4b519f32-1405-48f1-b985-822057743f2f", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// ANSWER - Test your solution\nrealityCheck(solution, spark, macroDataPath, investorsPath, targetDirectory)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "aa8d147c-d85e-418f-bf59-8004ad18a971", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "ae66ac75-2f9b-49b0-b46f-326c3e9bb8e5", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson.", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "67b09d1d-692e-4ca5-9a05-bd49d68a410a", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "1cc5cf86-97c1-41cf-bec7-7c778b535111", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Includes/Classroom-Cleanup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "3dddbb60-2638-4d98-88e7-c45046268744", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d65b8a83-cb14-40b8-8eb9-bdf2c5c202b5", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 10, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md\n## <img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps\n\nStart the next challenge, [Investors 2]($./PCF 08S - Investors 2)\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "c4f9a5cd-c110-4c62-afe0-5346b79e26d7", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "7f57f0bb-1125-4cdf-805d-4cbd0f24ba90", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 11, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "68dd9142-0faa-42f3-a935-67be1ab0e45b", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e47117e3-1d19-4949-9686-f7293454a520", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 12, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "03ece273-1cbf-4d50-9698-0e4961c28215", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF 07S - Investors", "origId": 0, "version": "NotebookV1"}