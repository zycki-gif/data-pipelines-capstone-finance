{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%run ./Classroom-Setup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "a9684631-2e28-42c8-b54f-fef5840dbfd1", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "a6b11f65-9d91-4c67-b106-f102f0044b17", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n// This cell comes before `Classroom Setup` so this notebook fails fast if the students failed to install the org.hsqldb:hsqldb:2.5.0 library.\n\ntry {\n  Class.forName(\"org.hsqldb.jdbc.JDBCDriver\")\n} catch {\n  case e: ClassNotFoundException =>\n    throw new java.sql.SQLException(\"Please install the HyperSQL library: org.hsqldb:hsqldb:2.5.0\").initCause(e)\n}\n\n/* dbutils.meta.define allows us to define a singleton inside a package then call displayHTML to suppress any output messages. */\ndbutils.meta.define(\"com.databricks.training\", \"\"\"\n  /**\n   Defines a HyperSQL database for use in training.  This wrapper ensures only one copy is running at any given time.\n  */\n  object ClassroomDB {\n    import org.hsqldb.server.Server\n    import org.hsqldb.persist.HsqlProperties\n    import org.apache.spark.sql.SparkSession\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.ResultSet;\n    import java.sql.Statement;\n\n    private var server : Server = null\n\n    private val serverProperties = new HsqlProperties();\n    {\n      serverProperties.setProperty(\"server.daemon\", \"true\")\n      serverProperties.setProperty(\"server.no_system_exit\", \"true\")\n      serverProperties.setProperty(\"server.remote_open\", \"false\")\n      serverProperties.setProperty(\"server.dbname.0\", \"classroom\")\n      serverProperties.setProperty(\"server.database.0\", \"mem\")\n      // serverProperties.setProperty(\"sql.syntax_mys\", \"true\") // NOT WORKING, SEE EXPLICIT QUERY FIX BELOW\n    }\n\n    val dbProps = new java.util.Properties()\n    dbProps.setProperty(\"driver\", \"org.hsqldb.jdbc.JDBCDriver\");\n    dbProps.setProperty(\"user\", \"SA\");\n    dbProps.setProperty(\"password\", \"\");\n\n    def jdbcURL(implicit spark : SparkSession) = {\n      val dbHostName = spark.conf.get(\"spark.driver.host\")\n      s\"jdbc:hsqldb:hsql://${dbHostName}/classroom\"\n    }\n\n    /** Starts database only if it's not already running. */\n    def start() : Unit = {\n      this.synchronized {\n        if (this.server != null && !this.server.isNotRunning)\n          return\n        this.server = new Server()\n        this.server.setProperties(serverProperties)\n        this.server.setErrWriter(null)\n        this.server.setLogWriter(null)\n        this.server.start()\n      }\n    }\n\n    def stop() : Unit = {\n      this.synchronized {\n        if (this.server != null && !server.isNotRunning)\n          this.server.shutdown\n        this.server = null\n      }\n    }\n    \n    /** Restarts database into a clean state, even if it is already running. */\n    def restart() : Unit = {\n      this.synchronized {\n        this.stop()\n        this.start()\n      }\n    }\n  }\n\"\"\")\n\ndisplayHTML(s\"Loaded database library.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "fe8565cd-5a11-4889-9d63-561dd3935324", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "56379635-61ad-4a94-97d4-f1712c0e2ff1", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\ncom.databricks.training.ClassroomDB.restart()\ndisplayHTML(s\"Started database.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "3a2c3067-d078-4a03-ac2d-0590e7ef0736", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e2e7da89-662b-45d0-8d43-af38d1422d0a", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n\ndef setMySQLCompatibility = {\n  import java.sql.DriverManager\n\n  val connProps = com.databricks.training.ClassroomDB.dbProps\n  val con = DriverManager.getConnection(\n    com.databricks.training.ClassroomDB.jdbcURL(spark),\n    connProps.get(\"user\").toString,\n    connProps.get(\"password\").toString)\n  val stmt = con.createStatement()\n  val result = stmt.executeQuery(\"SET DATABASE SQL SYNTAX MYS TRUE\")\n}\n\nsetMySQLCompatibility\ndisplayHTML(\"Set MySQL Compatibility Mode.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "cde75d89-6d4e-4717-abe7-d007a9a1b51a", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "26d0ee18-ec05-4a15-b50b-f7aeee7abf07", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%python\n\ninvestorsPath = financeDataPath + \"/investors/investors.parquet\"\ninvestors_raw = spark.read.option(\"inferSchema\", \"True\").option(\"header\",\"True\").parquet(investorsPath)\n\ntableName = \"investors\"\njdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ninvestors_raw.write.mode(\"overwrite\").jdbc(jdbcURL, tableName, properties=dbProps)\ndisplayHTML(\"Investors table created.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "c6d737b8-958b-491c-8e65-6a114dc95459", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "2d789fcf-a7dc-482a-848c-16efd82ff807", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "val targetDirectory = workingDir + \"/investors.delta\"\ncourseAdvertisements(\"targetDirectory\") = (\"v\", targetDirectory , targetDirectory)\nallDone(courseAdvertisements)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "70d315f6-edaf-4dfd-bcac-ab2a03b5846c", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "665af119-263f-419d-87c6-3391f99ea6e3", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// SETUP\nimport org.apache.spark.sql.SparkSession\ndef realityCheck(testMethod:(SparkSession, String) => DataFrame, spark:SparkSession, targetDirectory:String): Unit = {\n  import org.apache.spark.sql.functions._\n  import org.apache.spark.sql.types._\n  import java.io.ByteArrayOutputStream\n  \n  val resultDF = testMethod(spark, targetDirectory)\n  \n  val jdbcURL = com.databricks.training.ClassroomDB.jdbcURL(spark)\n  val dbProps = com.databricks.training.ClassroomDB.dbProps\n  val correctDF = spark.read.jdbc(\n      url=jdbcURL,                  // the JDBC URL\n      table=\"investors\",            // the name of the table\n      properties=dbProps)           // the connection properties\n \n  def read_delta() : DataFrame = {\n      try {\n        spark.read.format(\"delta\").load(targetDirectory)\n      } catch { \n        case _: Throwable => spark.emptyDataFrame \n      }\n  }\n  \n  val resultOutput = new ByteArrayOutputStream\n  val correctOutput = new ByteArrayOutputStream\n\n  Console.withOut(resultOutput) {testMethod(spark, targetDirectory)}\n  Console.withOut(correctOutput) {correctDF.show(10, truncate=false)}\n  \n  val deltaTable = read_delta()\n  \n  val tests = new TestSuite()\n    tests.addTest(TestCase(id=\"PCF-03B-A\", description=\"Returns correct schema\",\n             testFunction = () => compareSchemas(resultDF.schema, correctDF.schema, testColumnOrder=false, testNullable=false)))\n    tests.addTest(TestCase(id=\"PCF-03B-B\", description=\"Returns DataFrame with correct number of rows\",     \n             testFunction = () => resultDF.count == correctDF.count))\n    tests.addTest(TestCase(id=\"PCF-03B-C\", description=\"Returns DataFrame with correct results\", \n             testFunction = () => compareDataFramesLimited(resultDF, correctDF)))\n    tests.addTest(TestCase(id=\"PCF-03B-D\", description=\"Prints expected output\", \n             testFunction = () => resultOutput.toString contains correctOutput.toString))\n    tests.addTest(TestCase(id=\"PCF-03B-E\", description = \"Delta table in place\",\n             testFunction = () => !deltaTable.isEmpty))\n    tests.addTest(TestCase(id=\"PCF-03B-F\", description = \"Delta table has correct content\",\n             testFunction = () => compareDataFramesLimited(deltaTable, correctDF)))\n  \n   \n  tests.displayResults()\n  \n}\n\ndisplayHTML(\"\"\"\nDeclared the following function:\n  <li><span style=\"color:green; font-weight:bold\">realityCheck</span></li>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "d9319811-784a-4bae-84c7-d1b113e99024", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d62ad704-4ff2-493a-9d46-83f77326f18c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "val jdbcURL = com.databricks.training.ClassroomDB.jdbcURL(spark)\nval dbProps = com.databricks.training.ClassroomDB.dbProps\n\ndisplayHTML(s\"\"\"\n<h3>JDBC Connection Properties:</h3>\n<pre>\n  JDBC URL = ${jdbcURL}\n  Connection Properties: = ${dbProps}\n</pre>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "97e7981d-4d65-466a-9855-6c649fc66756", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "eef43660-c20a-4016-a5dc-afe4b651b833", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "displayHTML(\"All done!\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "fa9f0e80-8cb4-4303-ab78-fd385ddd6ba9", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "5d3b848a-2eff-4131-a75e-5d3a858df4cd", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "8904b848-8d43-44a0-be7a-8c199563d69b", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF-03B-ClassroomSetup", "origId": 0, "version": "NotebookV1"}