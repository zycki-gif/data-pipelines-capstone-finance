{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%run ./Classroom-Setup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "fb21434a-f63e-4b05-b630-13016c0b0308", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "a919410e-f532-4ec3-9f27-4e01be3abee2", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n// This cell comes before `Classroom Setup` so this notebook fails fast if the students failed to install the org.hsqldb:hsqldb:2.5.0 library.\n\ntry {\n  Class.forName(\"org.hsqldb.jdbc.JDBCDriver\")\n} catch {\n  case e: ClassNotFoundException =>\n    throw new java.sql.SQLException(\"Please install the HyperSQL library: org.hsqldb:hsqldb:2.5.0\").initCause(e)\n}\n\n/* dbutils.meta.define allows us to define a singleton inside a package then call displayHTML to suppress any output messages. */\ndbutils.meta.define(\"com.databricks.training\", \"\"\"\n  /**\n   Defines a HyperSQL database for use in training.  This wrapper ensures only one copy is running at any given time.\n  */\n  object ClassroomDB {\n    import org.hsqldb.server.Server\n    import org.hsqldb.persist.HsqlProperties\n    import org.apache.spark.sql.SparkSession\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.ResultSet;\n    import java.sql.Statement;\n\n    private var server : Server = null\n\n    private val serverProperties = new HsqlProperties();\n    {\n      serverProperties.setProperty(\"server.daemon\", \"true\")\n      serverProperties.setProperty(\"server.no_system_exit\", \"true\")\n      serverProperties.setProperty(\"server.remote_open\", \"false\")\n      serverProperties.setProperty(\"server.dbname.0\", \"classroom\")\n      serverProperties.setProperty(\"server.database.0\", \"mem\")\n      // serverProperties.setProperty(\"sql.syntax_mys\", \"true\") // NOT WORKING, SEE EXPLICIT QUERY FIX BELOW\n    }\n\n    val dbProps = new java.util.Properties()\n    dbProps.setProperty(\"driver\", \"org.hsqldb.jdbc.JDBCDriver\");\n    dbProps.setProperty(\"user\", \"SA\");\n    dbProps.setProperty(\"password\", \"\");\n\n    def jdbcURL(implicit spark : SparkSession) = {\n      val dbHostName = spark.conf.get(\"spark.driver.host\")\n      s\"jdbc:hsqldb:hsql://${dbHostName}/classroom\"\n    }\n\n    /** Starts database only if it's not already running. */\n    def start() : Unit = {\n      this.synchronized {\n        if (this.server != null && !this.server.isNotRunning)\n          return\n        this.server = new Server()\n        this.server.setProperties(serverProperties)\n        this.server.setErrWriter(null)\n        this.server.setLogWriter(null)\n        this.server.start()\n      }\n    }\n\n    def stop() : Unit = {\n      this.synchronized {\n        if (this.server != null && !server.isNotRunning)\n          this.server.shutdown\n        this.server = null\n      }\n    }\n    \n    /** Restarts database into a clean state, even if it is already running. */\n    def restart() : Unit = {\n      this.synchronized {\n        this.stop()\n        this.start()\n      }\n    }\n  }\n\"\"\")\n\ndisplayHTML(s\"Loaded database library.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "809ae35f-abb0-487b-8ae4-2174fb49d830", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "5bffd2de-311f-4d2f-945f-14fe94f27fc3", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\ncom.databricks.training.ClassroomDB.restart()\ndisplayHTML(s\"Started database.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "149593b0-0e4c-4d55-8a58-646e7980e902", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "0e1d871f-c4dd-4d83-8388-e4632bfdb9d7", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n\ndef setMySQLCompatibility = {\n  import java.sql.DriverManager\n\n  val connProps = com.databricks.training.ClassroomDB.dbProps\n  val con = DriverManager.getConnection(\n    com.databricks.training.ClassroomDB.jdbcURL(spark),\n    connProps.get(\"user\").toString,\n    connProps.get(\"password\").toString)\n  val stmt = con.createStatement()\n  val result = stmt.executeQuery(\"SET DATABASE SQL SYNTAX MYS TRUE\")\n}\n\nsetMySQLCompatibility\ndisplayHTML(\"Set MySQL Compatibility Mode.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "560a6cc1-340f-4990-95b1-8be3c6bda68c", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "f141503e-a54b-44e4-8b2e-06607f8465b8", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%python\n\ninvestorsPath = financeDataPath + \"/investors/investors.parquet\"\ninvestors_raw = spark.read.option(\"inferSchema\", \"True\").option(\"header\",\"True\").parquet(investorsPath)\n\ntableName = \"investors\"\njdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ninvestors_raw.write.mode(\"overwrite\").jdbc(jdbcURL, tableName, properties=dbProps)\ndisplayHTML(\"Investors table created.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "4025b6bd-7f14-4800-bdfb-9acfa90d6bf8", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "f63b4104-d050-474c-ac1b-72fd3ee3069d", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "val targetDirectory = workingDir + \"/investors.delta\"\ncourseAdvertisements(\"targetDirectory\") = (\"v\", targetDirectory , targetDirectory)\nallDone(courseAdvertisements)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "6cdf458f-eccd-4b99-aaa9-76c48c260fab", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "19b49a18-21b1-4db8-a8df-f5cae96a727d", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "// SETUP\nimport org.apache.spark.sql.SparkSession\ndef realityCheck(testMethod:(SparkSession, String) => DataFrame, spark:SparkSession, targetDirectory:String): Unit = {\n  import org.apache.spark.sql.functions._\n  import org.apache.spark.sql.types._\n  import java.io.ByteArrayOutputStream\n  \n  val resultDF = testMethod(spark, targetDirectory)\n  \n  val jdbcURL = com.databricks.training.ClassroomDB.jdbcURL(spark)\n  val dbProps = com.databricks.training.ClassroomDB.dbProps\n  val correctDF = spark.read.jdbc(\n      url=jdbcURL,                  // the JDBC URL\n      table=\"investors\",            // the name of the table\n      properties=dbProps)           // the connection properties\n \n  def read_delta() : DataFrame = {\n      try {\n        spark.read.format(\"delta\").load(targetDirectory)\n      } catch { \n        case _: Throwable => spark.emptyDataFrame \n      }\n  }\n  \n  val resultOutput = new ByteArrayOutputStream\n  val correctOutput = new ByteArrayOutputStream\n\n  Console.withOut(resultOutput) {testMethod(spark, targetDirectory)}\n  Console.withOut(correctOutput) {correctDF.show(10, truncate=false)}\n  \n  val deltaTable = read_delta()\n  \n  val tests = new TestSuite()\n    tests.addTest(TestCase(id=\"PCF-03B-A\", description=\"Returns correct schema\",\n             testFunction = () => compareSchemas(resultDF.schema, correctDF.schema, testColumnOrder=false, testNullable=false)))\n    tests.addTest(TestCase(id=\"PCF-03B-B\", description=\"Returns DataFrame with correct number of rows\",     \n             testFunction = () => resultDF.count == correctDF.count))\n    tests.addTest(TestCase(id=\"PCF-03B-C\", description=\"Returns DataFrame with correct results\", \n             testFunction = () => compareDataFramesLimited(resultDF, correctDF)))\n    tests.addTest(TestCase(id=\"PCF-03B-D\", description=\"Prints expected output\", \n             testFunction = () => resultOutput.toString contains correctOutput.toString))\n    tests.addTest(TestCase(id=\"PCF-03B-E\", description = \"Delta table in place\",\n             testFunction = () => !deltaTable.isEmpty))\n    tests.addTest(TestCase(id=\"PCF-03B-F\", description = \"Delta table has correct content\",\n             testFunction = () => compareDataFramesLimited(deltaTable, correctDF)))\n  \n   \n  tests.displayResults()\n  \n}\n\ndisplayHTML(\"\"\"\nDeclared the following function:\n  <li><span style=\"color:green; font-weight:bold\">realityCheck</span></li>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "232fe95a-2502-4d42-8e8e-f3a63e01bc2e", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "0a72fc4e-dbea-4ccb-a62e-c891f3b19f31", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "val jdbcURL = com.databricks.training.ClassroomDB.jdbcURL(spark)\nval dbProps = com.databricks.training.ClassroomDB.dbProps\n\ndisplayHTML(s\"\"\"\n<h3>JDBC Connection Properties:</h3>\n<pre>\n  JDBC URL = ${jdbcURL}\n  Connection Properties: = ${dbProps}\n</pre>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "04a1e40b-6d7e-4dd6-a372-e19b1b0fe65d", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "5b78b9f9-02da-4d4f-818d-82cf7a821c98", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "displayHTML(\"All done!\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "2df5a6b8-aea5-4839-81fc-5827e7915271", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "c43565bd-433c-42de-a7d6-3db1e655e529", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "baa93656-275c-402d-9361-4b372a7b5e77", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "PCF-03B-ClassroomSetup", "origId": 0, "version": "NotebookV1"}