{"commands": [{"bindings": {}, "collapsed": false, "command": "\nclass DummyData(val tableName: String, val defaultDatabaseName:String = databaseName, val seed: String = null, val numRows: Int = 300) {\n  import java.sql.Timestamp\n  import java.time.format.DateTimeFormatter\n  import java.time.LocalDateTime\n  import org.apache.spark.sql.DataFrame\n  import org.apache.spark.sql.functions.{broadcast, col, concat, date_format, explode, format_number, initcap, ltrim, monotonically_increasing_id, \n                                         lit, rand, randn, round, shuffle, split, udf, when, row_number}\n  import org.apache.spark.sql.expressions.Window\n  import org.apache.spark.sql.types.{IntegerType, TimestampType}\n  import scala.math.ceil\n  import scala.util.Random\n\n  // create database for user\n  private val username = getUsername()\n  private val userhome = getUserhome()\n  \n  private var dbName = defaultDatabaseName\n  dbName = dbName.replaceAll(\"[^a-zA-Z]\",\"\")\n  \n  spark.sql(\"CREATE DATABASE IF NOT EXISTS %s\".format(dbName))\n  \n  // set initial seed number\n  private var seedNum = if (seed != null) seed.hashCode else userhome.hashCode\n  \n  // initalize dataframe\n  private var id = \"id\"\n  private var df = spark.range(numRows).toDF\n  \n  // words reference\n  private val loremIpsum = \"amet luctus venenatis lectus magna fringilla urna porttitor rhoncus dolor purus non enim praesent elementum facilisis leo vel fringilla est ullamcorper eget nulla facilisi etiam dignissim diam quis enim lobortis scelerisque fermentum dui faucibus in ornare quam viverra orci sagittis eu volutpat odio facilisis mauris sit amet massa vitae tortor condimentum lacinia quis vel eros donec ac odio tempor orci dapibus ultrices in iaculis nunc sed augue lacus viverra vitae congue eu consequat ac felis donec et odio pellentesque diam volutpat commodo sed egestas egestas fringilla phasellus faucibus scelerisque eleifend donec pretium vulputate sapien nec sagittis aliquam malesuada bibendum arcu vitae elementum curabitur vitae nunc sed velit dignissim sodales ut eu sem integer vitae justo eget magna fermentum iaculis eu non diam phasellus vestibulum lorem sed risus ultricies tristique nulla aliquet enim tortor at auctor urna nunc id cursus metus aliquam eleifend mi in nulla posuere sollicitudin aliquam ultrices sagittis orci a scelerisque purus semper eget duis at tellus at urna condimentum mattis pellentesque id nibh tortor id aliquet lectus proin nibh nisl condimentum id venenatis a condimentum vitae sapien pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas sed tempus urna et pharetra pharetra massa\"\n  \n  // states reference\n  private val states = List(\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\n                    \"Illinois\",\"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\n                    \"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\n                    \"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\n                    \"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\")\n\n  private def getSeed(): Int = {\n    seedNum += 1\n    seedNum\n  }  \n  \n  def toDF(): DataFrame = {\n    val fullTableName = dbName + \".\" + tableName + \"_s\"\n    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fullTableName)\n    spark.read.table(fullTableName).orderBy(id)\n  }  \n  \n  def renameId(name: String): this.type = {\n    df = df.withColumnRenamed(id, name)\n    id = name\n    this\n  }\n  \n  // TODO: add option to drop an exact number of values - e.g. 6 nulls\n  def makeNull(name: String, proportion: Double = 0.2): this.type = {\n    df = addBooleans(\"_isNull\", proportion).df\n           .withColumn(name, when($\"_isNull\" === true, null)\n             .otherwise(col(name)))\n           .drop(\"_isNull\")\n    this\n  }\n  \n  def makeDuplicates(proportion: Double = 0.2): this.type = {\n    df = df.union(df.sample(proportion))\n    this\n  }\n  \n  def addIntegers(name: String, low: Double = 0, high: Double = 5000): this.type = {\n    df = df.withColumn(name, (rand(getSeed()) * (high - low) + low).cast(IntegerType))\n    this\n  }\n  \n  def addDoubles(name: String, low: Double = 0, high: Double = 5000, roundNum: Int = 6): this.type = {\n    df = df.withColumn(name, round(rand(getSeed()) * (high - low) + low, roundNum))\n    this\n  }\n\n  def addProportions(name: String, roundNum: Int = 6): this.type = {\n    df = df.withColumn(name, round(rand(getSeed()), roundNum))\n    this\n  }\n   \n  def addBooleans(name: String, proportionTrue: Double = 0.5): this.type = {\n    df = df.withColumn(name, rand(getSeed()) < proportionTrue)\n    this\n  }\n    \n  def addPriceDoubles(name: String, low: Double = 100, high: Double = 5000): this.type = {\n    df = df.withColumn(name, round(rand(getSeed()) * (high - low) + low, 2))\n    this\n  }\n    \n  def addPriceStrings(name: String, low: Double = 100, high: Double = 5000): this.type = {\n    df = df.withColumn(name, concat(lit(\"$\"), format_number(round(rand(getSeed()) * (high - low) + low, 2), 2)))\n    this\n  }\n    \n  def addCategories(name: String, categories: Seq[String] = Seq(\"first\", \"second\", \"third\", \"fourth\")): this.type = {\n\n    df = df.withColumn(name, (rand(getSeed()) * categories.size).cast(IntegerType))\n    val tempDF = categories.zipWithIndex.toDF(name + \"Text\", name)\n    df = df.join(broadcast(tempDF), name).drop(name).withColumnRenamed(name + \"Text\", name)\n       \n    this\n  }\n  \n  def addPasswords(name: String = \"password\"): this.type = {\n    val w = Window.orderBy(lit(\"A\"))\n    val passwords = for (row <- df.collect()) \n      yield new scala.util.Random().alphanumeric.take(8 + new scala.util.Random().nextInt(20 - 8) + 1).mkString(\"\")\n    val passwordDF = passwords.toList\n                              .toDF()\n                              .withColumnRenamed(\"value\", name)\n                              .withColumn(\"row_num\", row_number().over(w))\n    \n    df = df.withColumn(\"row_num\", row_number().over(w))\n    df = df.join(passwordDF, \"row_num\").drop(\"row_num\")\n    this\n  }\n    \n  def addWords(name: String, num: Int = 5): this.type = {\n    val loremCount = loremIpsum.split(\" \").length\n    val words = (loremIpsum + \" \") * ceil(numRows / loremCount.toDouble).toInt\n    val word_list = words.split(\" \").toList\n    \n    // needs to be done: implement worsDF creation using spark/DF to scale\n    \n    df = df.withColumn(name, lit(\"\"))\n    \n    val randomGen = new Random(getSeed())\n    for (i <- 1 to num) {\n      val wordsDF = spark.createDataset(randomGen.shuffle(word_list).zipWithIndex)\n                         .toDF(\"word\" + i.toString, id)\n                         .sort(id)\n                         .limit(numRows)\n      \n      df = df.join(wordsDF, id)\n             .withColumn(name, concat(col(name), lit(\" \"), col(\"word\" + i.toString)))\n             .drop(\"word\" + i.toString)\n    }\n\n    df = df.withColumn(name, ltrim(col(name)))\n    this\n  }\n    \n  def addNames(name: String, num: Int = 2): this.type = {\n    df = addWords(name, num).df.withColumn(name, initcap(col(name)))\n    this\n  }\n    \n  def addWordArrays(name: String, num: Int = 5): this.type = {\n    df = addWords(name, num).df.withColumn(name, split(col(name), \" \"))\n    this\n  }\n\n  def addTimestamps(name: String, start_date_expr: String = \"2015-08-05 12:00:00\", end_date_expr: String = \"2019-08-05 12:00:00\", format: String = \"yyyy-MM-dd HH:mm:ss\"): this.type = {\n    val formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")\n    val start_timestamp = Timestamp.valueOf(LocalDateTime.parse(start_date_expr, formatter)).getTime() / 1000\n    val end_timestamp = Timestamp.valueOf(LocalDateTime.parse(end_date_expr, formatter)).getTime() / 1000\n    df = addIntegers(name, start_timestamp, end_timestamp).df\n    this\n  }\n  \n  def addDateStrings(name: String, start_date_expr: String = \"2015-08-05 12:00:00\", end_date_expr: String = \"2019-08-05 12:00:00\", format: String = \"yyyy-MM-dd HH:mm:ss\"): this.type = {\n    df = addTimestamps(name, start_date_expr, end_date_expr).df\n           .withColumn(name, date_format(col(name).cast(TimestampType), format))\n    this\n  }\n  \n  def addStates(name: String): this.type = {\n    df = addCategories(name, this.states).df\n    this\n  }\n\n  // needs to be done: add probabilities to categories\n  // needs to be done: add arrays of all types\n  // needs to be done: add normal distribution, skewed data\n  // needs to be done: add data dependent on another column\n  \n}\n\ndisplayHTML(\"Initializing Databricks Academy's services for generating dynamic data...\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "da1b3f1f-632b-4a1c-8206-5f8d27bccabd", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "787ff57e-4a0b-45fd-9ff3-f3600ca8d08a", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "67c4e88b-8920-431b-af43-5fb8918b1a7e", "iPythonMetadata": null, "inputWidgets": {}, "language": "scala", "name": "Dummy-Data-Generator", "origId": 0, "version": "NotebookV1"}