{"commands": [{"bindings": {}, "collapsed": false, "command": "\nclass DummyData:\n  from datetime import datetime\n  from pyspark.sql import DataFrame\n  from pyspark.sql import functions\n  from pyspark.sql.window import Window\n  from pyspark.sql.types import IntegerType, StringType, TimestampType, NullType\n  from math import ceil\n  from string import ascii_letters, digits\n  import pyspark.sql.functions as F\n  import re, random\n\n  \n  def __init__(self, tableName, defaultDatabaseName=databaseName, seed=None, numRows=300):\n    \n    self.__tableName = tableName\n    self.__numRows = numRows\n    \n    # create database for user\n    username = getUsername()\n    userhome = getUserhome()\n\n    self.__dbName = defaultDatabaseName\n    self.__dbName = self.re.sub(\"[^a-zA-Z]\", \"\", self.__dbName)\n\n    spark.sql(\"CREATE DATABASE IF NOT EXISTS {}\".format(self.__dbName))\n\n    # set initial seed number\n    seed = userhome if seed is None else seed\n    self.__seedNum = hash(seed)\n      \n    # initialize dataframe\n    self.__id = \"id\"\n    self.__df = spark.range(self.__numRows)\n    \n    # words reference\n    self.__loremIpsum = \"amet luctus venenatis lectus magna fringilla urna porttitor rhoncus dolor purus non enim praesent elementum facilisis leo vel fringilla est ullamcorper eget nulla facilisi etiam dignissim diam quis enim lobortis scelerisque fermentum dui faucibus in ornare quam viverra orci sagittis eu volutpat odio facilisis mauris sit amet massa vitae tortor condimentum lacinia quis vel eros donec ac odio tempor orci dapibus ultrices in iaculis nunc sed augue lacus viverra vitae congue eu consequat ac felis donec et odio pellentesque diam volutpat commodo sed egestas egestas fringilla phasellus faucibus scelerisque eleifend donec pretium vulputate sapien nec sagittis aliquam malesuada bibendum arcu vitae elementum curabitur vitae nunc sed velit dignissim sodales ut eu sem integer vitae justo eget magna fermentum iaculis eu non diam phasellus vestibulum lorem sed risus ultricies tristique nulla aliquet enim tortor at auctor urna nunc id cursus metus aliquam eleifend mi in nulla posuere sollicitudin aliquam ultrices sagittis orci a scelerisque purus semper eget duis at tellus at urna condimentum mattis pellentesque id nibh tortor id aliquet lectus proin nibh nisl condimentum id venenatis a condimentum vitae sapien pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas sed tempus urna et pharetra pharetra massa\"\n    \n    # states reference\n    self.__states = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\n                     \"Illinois\",\"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\n                     \"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\n                     \"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\n                     \"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n    \n    # chars reference\n    self.__chars = self.ascii_letters + self.digits\n    \n  def __getSeed(self):\n    self.__seedNum += 1\n    return self.__seedNum  \n    \n  def toDF(self):\n    fullTableName = self.__dbName + \".\" + self.__tableName + \"_p\"\n    self.__df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fullTableName)\n    return spark.read.table(fullTableName).orderBy(self.__id)\n  \n  def renameId(self, name):\n    self.__df = self.__df.withColumnRenamed(self.__id, name)\n    self.__id = name\n    return self\n  \n  def makeNull(self, name, proportion = 0.2): \n    self.__df = (self.addBooleans(\"_isNull\", proportion).__df\n           .withColumn(name, self.F.when(self.F.col(\"_isNull\") == True, None)\n           .otherwise(self.F.col(name)))\n           .drop(\"_isNull\"))\n    return self\n  \n  def addIntegers(self, name: str, low: float = 0, high: float = 5000):\n    self.__df = self.__df.withColumn(name, (self.F.rand(self.__getSeed()) * (high - low) + low).cast(self.IntegerType()))\n    return self\n  \n  def addDoubles(self, name, low = 0, high = 5000, roundNum = 6):\n    self.__df = self.__df.withColumn(name, self.F.round(self.F.rand(self.__getSeed()) * (high - low) + low, roundNum))\n    return self\n\n  def addProportions(self, name, roundNum = 6):\n    self.__df = self.__df.withColumn(name, self.F.round(self.F.rand(self.__getSeed()), roundNum))\n    return self\n   \n  def addBooleans(self, name, proportionTrue = 0.5):\n    self.__df = self.__df.withColumn(name, self.F.rand(self.__getSeed()) < proportionTrue)\n    return self\n    \n  def addPriceDoubles(self, name, low = 100, high = 5000):\n    self.__df = self.__df.withColumn(name, self.F.round(self.F.rand(self.__getSeed()) * (high - low) + low, 2))\n    return self\n    \n  def addPriceStrings(self, name, low = 100, high = 5000):\n    self.__df = self.__df.withColumn(name, self.F.format_number(self.F.round(self.F.rand(self.__getSeed()) * (high - low) + low, 2), 2))\n    self.__df = self.__df.withColumn(name, self.F.concat(self.F.lit(\"$\"), name))\n    return self\n  \n  def addCategories(self, name, categories = [\"first\", \"second\", \"third\", \"fourth\"]):\n    self.__df = self.__df.withColumn(name, (self.F.rand(self.__getSeed()) * len(categories)).cast(self.IntegerType()))\n    tempDF = sqlContext.createDataFrame(zip(range(len(categories)), categories), schema=[name, name + \"Text\"])\n    self.__df = self.__df.join(self.F.broadcast(tempDF), name)\n    self.__df = self.__df.drop(name)\n    self.__df = self.__df.withColumnRenamed(name + \"Text\", name)\n    return self\n  \n  def addPasswords(self, name: str = \"password\"):\n    w = self.Window().orderBy(self.F.lit('A'))\n    passwordDF = (spark\n                    .createDataFrame(\n                      [''.join(self.__chars[self.random.randint(0, len(self.__chars) - 1)] for i in range(8,20)) for x in range(self.__numRows)], \n                      schema = StringType()\n                    )\n                    .withColumnRenamed(\"value\", name)\n                    .withColumn(\"row_num\", self.F.row_number().over(w)))\n    \n    self.__df = self.__df.withColumn(\"row_num\", self.F.row_number().over(w))\n    self.__df = self.__df.join(passwordDF, \"row_num\").drop(\"row_num\")\n    return self\n  \n  def addWords(self, name, num = 5):\n    loremCount = len(self.__loremIpsum.split(\" \"))\n    words = (self.__loremIpsum + \" \") * int(self.ceil(self.__numRows / float(loremCount)))\n    word_list = words.split(\" \")\n    \n    self.__df = self.__df.withColumn(name, self.F.lit(\"\"))\n    self.random.seed(self.__getSeed())\n    \n    for i in range(num):\n      self.random.shuffle(word_list)\n      word_data = list(zip(word_list, range(0, len(word_list))))\n      \n      wordsDF = (spark.createDataFrame(word_data, [\"word\" + str(i), self.__id])\n                      .sort(self.__id).limit(self.__numRows))\n      \n      self.__df = (self.__df.join(wordsDF, self.__id)\n                       .withColumn(name, self.F.concat(self.F.col(name), self.F.lit(\" \"), self.F.col(\"word\" + str(i))))\n                       .drop(\"word\" + str(i)))\n      \n    self.__df = self.__df.withColumn(name, self.F.ltrim(self.F.col(name)))\n    return self\n    \n  def addNames(self, name, num = 2):\n    self.__df = self.addWords(name, num).__df.withColumn(name, self.F.initcap(self.F.col(name)))\n    return self\n    \n  def addWordArrays(self, name, num = 5):\n    self.__df = self.addWords(name, num).__df.withColumn(name, self.F.split(self.F.col(name), \" \"))\n    return self\n\n  def addTimestamps(self, name, start_date_expr = \"2015-08-05 12:00:00\", end_date_expr = \"2019-08-05 12:00:00\", format = \"%Y-%m-%d %H:%M:%S\"):\n    start_timestamp = self.datetime.strptime(start_date_expr, format).timestamp()\n    end_timestamp = self.datetime.strptime(end_date_expr, format).timestamp()\n    self.__df = self.addIntegers(name, start_timestamp, end_timestamp).__df\n    return self\n  \n  def addDateStrings(self, name, start_date_expr = \"2015-08-05 12:00:00\", end_date_expr = \"2019-08-05 12:00:00\", format = \"yyyy-MM-dd HH:mm:ss\"):\n    self.__df = (self.addTimestamps(name, start_date_expr, end_date_expr).__df\n                     .withColumn(name, self.F.date_format(self.F.col(name).cast(self.TimestampType()), format)))\n    return self\n  \n  def addStates(self, name):\n    self.__df = self.addCategories(name, self.__states).__df\n    return self\n  \n  # needs to be done: add probabilities to categories\n  # needs to be done: add arrays of all types\n  # needs to be done: add normal distribution, skewed data\n  # needs to be done: add data dependent on another column\n\ndisplayHTML(\"Initializing Databricks Academy's services for generating dynamic data...\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "62744fc5-2097-499c-9642-7f0655926214", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "2c7fe94c-f4ff-4a53-b5d2-c23c37062fc5", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "2aec24cc-0d6a-4248-9ca5-8d35d57bf9e3", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "Dummy-Data-Generator", "origId": 0, "version": "NotebookV1"}