{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%run ./Classroom-Setup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "98d93c0b-4682-4c99-b73a-b5547848ec76", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "50caf350-3203-4bc9-9263-64499062700a", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n// This cell comes before `Classroom Setup` so this notebook fails fast if the students failed to install the org.hsqldb:hsqldb:2.5.0 library.\n\ntry {\n  Class.forName(\"org.hsqldb.jdbc.JDBCDriver\")\n} catch {\n  case e: ClassNotFoundException =>\n    throw new java.sql.SQLException(\"Please install the HyperSQL library: org.hsqldb:hsqldb:2.5.0\").initCause(e)\n}\n\n/* dbutils.meta.define allows us to define a singleton inside a package then call displayHTML to suppress any output messages. */\ndbutils.meta.define(\"com.databricks.training\", \"\"\"\n  /**\n   Defines a HyperSQL database for use in training.  This wrapper ensures only one copy is running at any given time.\n  */\n  object ClassroomDB {\n    import org.hsqldb.server.Server\n    import org.hsqldb.persist.HsqlProperties\n    import org.apache.spark.sql.SparkSession\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.ResultSet;\n    import java.sql.Statement;\n\n    private var server : Server = null\n\n    private val serverProperties = new HsqlProperties();\n    {\n      serverProperties.setProperty(\"server.daemon\", \"true\")\n      serverProperties.setProperty(\"server.no_system_exit\", \"true\")\n      serverProperties.setProperty(\"server.remote_open\", \"false\")\n      serverProperties.setProperty(\"server.dbname.0\", \"classroom\")\n      serverProperties.setProperty(\"server.database.0\", \"mem\")\n      // serverProperties.setProperty(\"sql.syntax_mys\", \"true\") // NOT WORKING, SEE EXPLICIT QUERY FIX BELOW\n    }\n\n    val dbProps = new java.util.Properties()\n    dbProps.setProperty(\"driver\", \"org.hsqldb.jdbc.JDBCDriver\");\n    dbProps.setProperty(\"user\", \"SA\");\n    dbProps.setProperty(\"password\", \"\");\n\n    def jdbcURL(implicit spark : SparkSession) = {\n      val dbHostName = spark.conf.get(\"spark.driver.host\")\n      s\"jdbc:hsqldb:hsql://${dbHostName}/classroom\"\n    }\n\n    /** Starts database only if it's not already running. */\n    def start() : Unit = {\n      this.synchronized {\n        if (this.server != null && !this.server.isNotRunning)\n          return\n        this.server = new Server()\n        this.server.setProperties(serverProperties)\n        this.server.setErrWriter(null)\n        this.server.setLogWriter(null)\n        this.server.start()\n      }\n    }\n\n    def stop() : Unit = {\n      this.synchronized {\n        if (this.server != null && !server.isNotRunning)\n          this.server.shutdown\n        this.server = null\n      }\n    }\n    \n    /** Restarts database into a clean state, even if it is already running. */\n    def restart() : Unit = {\n      this.synchronized {\n        this.stop()\n        this.start()\n      }\n    }\n  }\n\"\"\")\n\ndisplayHTML(s\"Loaded database library.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "12f3356b-e691-4c25-a756-16b41f6ba8e1", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "e84e3062-74e9-4897-be38-5d7fc611941e", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\ncom.databricks.training.ClassroomDB.restart()\ndisplayHTML(s\"Started database.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "8a2db172-9fe9-4d2c-b529-d0066434b96f", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "481e29c7-0e11-43c4-a357-881398935707", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n\ndef setMySQLCompatibility = {\n  import java.sql.DriverManager\n\n  val connProps = com.databricks.training.ClassroomDB.dbProps\n  val con = DriverManager.getConnection(\n    com.databricks.training.ClassroomDB.jdbcURL(spark),\n    connProps.get(\"user\").toString,\n    connProps.get(\"password\").toString)\n  val stmt = con.createStatement()\n  val result = stmt.executeQuery(\"SET DATABASE SQL SYNTAX MYS TRUE\")\n}\n\nsetMySQLCompatibility\ndisplayHTML(\"Set MySQL Compatibility Mode.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "b523c86f-6998-4b58-bc78-19eb7add5673", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "4e5cbe3b-d03c-474c-b3b1-efc5ac223911", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%python\n\ninvestorsPath = financeDataPath + \"/investors/investors.parquet\"\ninvestors_raw = spark.read.option(\"inferSchema\", \"True\").option(\"header\",\"True\").parquet(investorsPath)\n\ntableName = \"investors\"\njdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ninvestors_raw.write.mode(\"overwrite\").jdbc(jdbcURL, tableName, properties=dbProps)\ndisplayHTML(\"Investors table created.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "b6b32234-93fc-4a69-91f8-f924ed72257f", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "19030ceb-bdbf-40ca-831f-e510702341fd", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "targetDirectory = workingDir + \"/investors/investors.delta\"\ncourseAdvertisements[\"targetDirectory\"] = (\"v\", targetDirectory , targetDirectory)\nallDone(courseAdvertisements)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "d2164e94-aede-4f24-8e93-645b040ea2b4", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "02727bb9-dd74-4f02-ae98-7ce092b5fa28", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "# SETUP\n\ndef realityCheck(testMethod, spark, targetDirectory):\n  from contextlib import redirect_stdout\n  from io import StringIO\n  from pyspark.sql.functions import col\n  \n  dumpOutput = StringIO()\n  with redirect_stdout(dumpOutput):\n    correctDF = spark.read.jdbc(\n      url=jdbcURL,                  # the JDBC URL\n      table=\"investors\",            # the name of the table\n      properties=dbProps)           # the connection properties\n \n  def read_delta():\n    try:\n      return spark.read.format(\"delta\").load(targetDirectory)\n    except Exception:\n      return None\n  \n  deltaTable = read_delta()\n\n  resultOutput = StringIO()\n  with redirect_stdout(resultOutput):\n    resultDF = testMethod(spark, targetDirectory)\n  resultOutput = resultOutput.getvalue()\n  \n  correctOutput = StringIO()\n  with redirect_stdout(correctOutput):\n    correctDF.show(10, truncate=False)\n  correctOutput = correctOutput.getvalue()\n  \n  updateSourceDataInDevMode(correctDF, \"bronze/investors\")\n\n  tests = TestSuite()\n\n  tests.addTest(TestCase(id=\"PCF-03B-A\", description = \"Returns correct schema\", \n           testFunction = lambda: compareSchemas(resultDF.schema, correctDF.schema, testColumnOrder=False, testNullable=False))),\n  tests.addTest(TestCase(id=\"PCF-03B-B\", description = \"Returns DataFrame with correct number of rows\",              \n           testFunction = lambda: resultDF.count() == correctDF.count())),\n  tests.addTest(TestCase(id=\"PCF-03B-C\", description = \"Returns DataFrame with correct results\", \n           testFunction = lambda: compareDataFramesLimited(resultDF, correctDF))),\n  tests.addTest(TestCase(id=\"PCF-03B-D\", description = \"Prints expected output\", \n           testFunction = lambda: correctOutput in resultOutput and resultOutput in correctOutput)),\n  tests.addTest(TestCase(id=\"PCF-03B-E\", description = \"Delta table in place\",\n           testFunction = lambda: deltaTable is not None)),\n  tests.addTest(TestCase(id=\"PCF-03B-F\", description = \"Delta table has correct content\",\n           testFunction = lambda: compareDataFramesLimited(deltaTable, correctDF)))\n\n  tests.displayResults()\n  \ndisplayHTML(\"\"\"\nDeclared the following function:\n  <li><span style=\"color:green; font-weight:bold\">realityCheck</span></li>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "d48c986a-db98-4f80-b3f4-89dd2dacc581", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "843e549b-2dc6-4072-805c-108a322f148c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "jdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ndisplayHTML(\"\"\"\n<h3>JDBC Connection Properties:</h3>\n<pre>\n  JDBC URL = {jdbcURL!r}\n  Connection Properties: = {dbProps!r}\n</pre>\n\"\"\".format(**globals()))", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "8d0039a9-7f22-4601-8079-ddd078113077", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "b1556413-9cd6-40ac-b853-825348804e23", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "displayHTML(\"All done!\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "f152b9c9-52f2-4f5c-b5e8-2883ac43e6c4", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d292e6b5-d563-48b3-be4f-8117c957ec97", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "8f63d625-0022-4bba-92d2-882383f1546b", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "PCF-03B-ClassroomSetup", "origId": 0, "version": "NotebookV1"}