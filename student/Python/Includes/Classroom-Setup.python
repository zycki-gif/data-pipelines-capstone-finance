{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%python\n# We need the python version of financeDataPath in 03B - it has an ALL_NOTEBOOKS Python code which needs to be execute\n# There shouldn't be anything else in this cell that would vary between Python and Scala doing this to the whole cell should be OK\n\nfinanceDataPath = \"dbfs:/mnt/training/finance-org\"\n\nspark.conf.set(\"com.databricks.training.module-name\", \"capstone-finance\")\n\nspark.conf.set(\"com.databricks.training.suppress.untilStreamIsReady\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.stopAllStreams\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.moduleName\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.lessonName\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.username\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.userhome\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.workingDir\", \"true\")\n\ndisplayHTML(\"Preparing the learning environment...\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "eb6d7696-4c36-4129-b21c-0d9580ff6992", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "d054d002-e780-4f7b-b30f-5ebc5d7a8634", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Common-Notebooks/Common", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "db2bc16c-8029-4804-bc6d-268e12315d0d", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "11fec3f6-f1d0-4646-a946-27bbf33d7067", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "courseAdvertisements[\"financeDataPath\"] = (\"v\", financeDataPath, \"The location of the finance dataset used in this capstone project.\")\n\nsourceDataPath = financeDataPath + \"/solutions\"\ncourseAdvertisements[\"sourceDataPath\"] = (\"v\", sourceDataPath, \"The location of the specific datasets used in this capstone project as source data.\")\n\nimport pyspark\n\n# This should be commented out by default. Use if only when developing the courseware.\n# This function recreates notebook target datasets as reference datasets.\n\ndef updateSourceDataInDevMode(df, pathSuffix):\n  return\n  path = sourceDataPath + \"/\" + pathSuffix\n  dbutils.fs.rm(path, True)\n  df.write.mode(\"overwrite\").option(\"overwriteSchema\", True).format(\"delta\").save(path)\n\n  displayHTML(\"\"\"\n  <div style=\"padding:1em; border: 5px solid red\">\n      <div>Recreated dataset from reference data: \"\"\" + path + \"\"\"</div>\n  </div>\n\"\"\")\n  \ndef roundDataFrame(df):\n  res = df\n  for c in df.schema:\n    if ((c.dataType == pyspark.sql.types.DoubleType()) \n        or (c.dataType == pyspark.sql.types.FloatType())):\n      res = res.withColumn(c.name, pyspark.sql.functions.floor(pyspark.sql.functions.col(c.name)))\n  return res\n\ndef compareDataFramesLimited(df1:pyspark.sql.DataFrame, df2:pyspark.sql.DataFrame) -> bool:\n  sortedColumns1 = sorted(df1.columns)\n  df1Sorted = df1.select(sortedColumns1).orderBy(sortedColumns1).limit(10000)\n  \n  sortedColumns2 = sorted(df2.columns)\n  df2Sorted = df2.select(sortedColumns2).orderBy(sortedColumns2).limit(10000)\n\n  return compareDataFrames(roundDataFrame(df1Sorted), roundDataFrame(df2Sorted), testColumnOrder=True, testNullable=False)\n\ndisplayHTML(\"Finalizing the learning environment...\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "46073d75-6777-47fa-9eec-357d311c47b5", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "3fc4d5c2-9702-4ef7-a8e7-e549a8465909", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "33a694a2-fe09-4f12-9eec-c35f67a2eace", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "Classroom-Setup", "origId": 0, "version": "NotebookV1"}