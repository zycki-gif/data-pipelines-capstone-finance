{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%python\n# We need the python version of financeDataPath in 03B - it has an ALL_NOTEBOOKS Python code which needs to be execute\n# There shouldn't be anything else in this cell that would vary between Python and Scala doing this to the whole cell should be OK\n\nfinanceDataPath = \"dbfs:/mnt/training/finance-org\"\n\nspark.conf.set(\"com.databricks.training.module-name\", \"capstone-finance\")\n\nspark.conf.set(\"com.databricks.training.suppress.untilStreamIsReady\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.stopAllStreams\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.moduleName\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.lessonName\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.username\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.userhome\", \"true\")\nspark.conf.set(\"com.databricks.training.suppress.workingDir\", \"true\")\n\ndisplayHTML(\"Preparing the learning environment...\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "186863db-6ea2-4254-b99d-dfd4147154cc", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "f05a4f99-84e7-4fbe-beac-ec2abc3b985c", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%run ./Common-Notebooks/Common", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "b1399f16-1816-40dc-808f-ecde683e2b82", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "25c3886c-f145-4ab2-9a8b-fa50600ff432", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "courseAdvertisements[\"financeDataPath\"] = (\"v\", financeDataPath, \"The location of the finance dataset used in this capstone project.\")\n\nsourceDataPath = financeDataPath + \"/solutions\"\ncourseAdvertisements[\"sourceDataPath\"] = (\"v\", sourceDataPath, \"The location of the specific datasets used in this capstone project as source data.\")\n\nimport pyspark\n\n# This should be commented out by default. Use if only when developing the courseware.\n# This function recreates notebook target datasets as reference datasets.\n\ndef updateSourceDataInDevMode(df, pathSuffix):\n  return\n  path = sourceDataPath + \"/\" + pathSuffix\n  dbutils.fs.rm(path, True)\n  df.write.mode(\"overwrite\").option(\"overwriteSchema\", True).format(\"delta\").save(path)\n\n  displayHTML(\"\"\"\n  <div style=\"padding:1em; border: 5px solid red\">\n      <div>Recreated dataset from reference data: \"\"\" + path + \"\"\"</div>\n  </div>\n\"\"\")\n  \ndef roundDataFrame(df):\n  res = df\n  for c in df.schema:\n    if ((c.dataType == pyspark.sql.types.DoubleType()) \n        or (c.dataType == pyspark.sql.types.FloatType())):\n      res = res.withColumn(c.name, pyspark.sql.functions.floor(pyspark.sql.functions.col(c.name)))\n  return res\n\ndef compareDataFramesLimited(df1:pyspark.sql.DataFrame, df2:pyspark.sql.DataFrame) -> bool:\n  sortedColumns1 = sorted(df1.columns)\n  df1Sorted = df1.select(sortedColumns1).orderBy(sortedColumns1).limit(10000)\n  \n  sortedColumns2 = sorted(df2.columns)\n  df2Sorted = df2.select(sortedColumns2).orderBy(sortedColumns2).limit(10000)\n\n  return compareDataFrames(roundDataFrame(df1Sorted), roundDataFrame(df2Sorted), testColumnOrder=True, testNullable=False)\n\ndisplayHTML(\"Finalizing the learning environment...\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "e12b3472-e1ab-4100-a8af-e13f50c8a431", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "c4a74463-8c04-44f4-9b8b-19d934f7b874", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "14d983c6-7223-4f2d-9a75-369837f6954b", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "Classroom-Setup", "origId": 0, "version": "NotebookV1"}