{"commands": [{"bindings": {}, "collapsed": false, "command": "\n%run ./Classroom-Setup", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "97fbf6ab-b3bb-4a2b-afb9-1ec95a38cc2f", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "5d1840d8-029c-4561-9bc6-9c293394ef17", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 1, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n// This cell comes before `Classroom Setup` so this notebook fails fast if the students failed to install the org.hsqldb:hsqldb:2.5.0 library.\n\ntry {\n  Class.forName(\"org.hsqldb.jdbc.JDBCDriver\")\n} catch {\n  case e: ClassNotFoundException =>\n    throw new java.sql.SQLException(\"Please install the HyperSQL library: org.hsqldb:hsqldb:2.5.0\").initCause(e)\n}\n\n/* dbutils.meta.define allows us to define a singleton inside a package then call displayHTML to suppress any output messages. */\ndbutils.meta.define(\"com.databricks.training\", \"\"\"\n  /**\n   Defines a HyperSQL database for use in training.  This wrapper ensures only one copy is running at any given time.\n  */\n  object ClassroomDB {\n    import org.hsqldb.server.Server\n    import org.hsqldb.persist.HsqlProperties\n    import org.apache.spark.sql.SparkSession\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.ResultSet;\n    import java.sql.Statement;\n\n    private var server : Server = null\n\n    private val serverProperties = new HsqlProperties();\n    {\n      serverProperties.setProperty(\"server.daemon\", \"true\")\n      serverProperties.setProperty(\"server.no_system_exit\", \"true\")\n      serverProperties.setProperty(\"server.remote_open\", \"false\")\n      serverProperties.setProperty(\"server.dbname.0\", \"classroom\")\n      serverProperties.setProperty(\"server.database.0\", \"mem\")\n      // serverProperties.setProperty(\"sql.syntax_mys\", \"true\") // NOT WORKING, SEE EXPLICIT QUERY FIX BELOW\n    }\n\n    val dbProps = new java.util.Properties()\n    dbProps.setProperty(\"driver\", \"org.hsqldb.jdbc.JDBCDriver\");\n    dbProps.setProperty(\"user\", \"SA\");\n    dbProps.setProperty(\"password\", \"\");\n\n    def jdbcURL(implicit spark : SparkSession) = {\n      val dbHostName = spark.conf.get(\"spark.driver.host\")\n      s\"jdbc:hsqldb:hsql://${dbHostName}/classroom\"\n    }\n\n    /** Starts database only if it's not already running. */\n    def start() : Unit = {\n      this.synchronized {\n        if (this.server != null && !this.server.isNotRunning)\n          return\n        this.server = new Server()\n        this.server.setProperties(serverProperties)\n        this.server.setErrWriter(null)\n        this.server.setLogWriter(null)\n        this.server.start()\n      }\n    }\n\n    def stop() : Unit = {\n      this.synchronized {\n        if (this.server != null && !server.isNotRunning)\n          this.server.shutdown\n        this.server = null\n      }\n    }\n    \n    /** Restarts database into a clean state, even if it is already running. */\n    def restart() : Unit = {\n      this.synchronized {\n        this.stop()\n        this.start()\n      }\n    }\n  }\n\"\"\")\n\ndisplayHTML(s\"Loaded database library.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "afd769cf-3947-475f-99fe-2b4a19905418", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "c0c6cbc5-1954-41eb-bd99-ddd9199c15fe", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 2, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\ncom.databricks.training.ClassroomDB.restart()\ndisplayHTML(s\"Started database.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "14d00933-4607-4cbf-aea1-6f3435299fab", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "3f4f7866-8736-4e06-9c23-0e52eb3fb72b", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 3, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%scala\n\ndef setMySQLCompatibility = {\n  import java.sql.DriverManager\n\n  val connProps = com.databricks.training.ClassroomDB.dbProps\n  val con = DriverManager.getConnection(\n    com.databricks.training.ClassroomDB.jdbcURL(spark),\n    connProps.get(\"user\").toString,\n    connProps.get(\"password\").toString)\n  val stmt = con.createStatement()\n  val result = stmt.executeQuery(\"SET DATABASE SQL SYNTAX MYS TRUE\")\n}\n\nsetMySQLCompatibility\ndisplayHTML(\"Set MySQL Compatibility Mode.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "986dc0ba-c167-41f5-bbf5-ee06501c15dc", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "a0b1cd07-afac-4225-b3b4-75fa9c7398d4", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 4, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "%python\n\ninvestorsPath = financeDataPath + \"/investors/investors.parquet\"\ninvestors_raw = spark.read.option(\"inferSchema\", \"True\").option(\"header\",\"True\").parquet(investorsPath)\n\ntableName = \"investors\"\njdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ninvestors_raw.write.mode(\"overwrite\").jdbc(jdbcURL, tableName, properties=dbProps)\ndisplayHTML(\"Investors table created.\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "56b7d216-a341-4e41-8a0d-eac712592a14", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "70e86f7a-f82f-44da-861b-f746539b66a8", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 5, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "targetDirectory = workingDir + \"/investors/investors.delta\"\ncourseAdvertisements[\"targetDirectory\"] = (\"v\", targetDirectory , targetDirectory)\nallDone(courseAdvertisements)", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "a6da4c91-7326-4bcd-ab5e-3497d9c56126", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "c51fdff5-2210-4caf-b779-617573322d6b", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 6, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "# SETUP\n\ndef realityCheck(testMethod, spark, targetDirectory):\n  from contextlib import redirect_stdout\n  from io import StringIO\n  from pyspark.sql.functions import col\n  \n  dumpOutput = StringIO()\n  with redirect_stdout(dumpOutput):\n    correctDF = spark.read.jdbc(\n      url=jdbcURL,                  # the JDBC URL\n      table=\"investors\",            # the name of the table\n      properties=dbProps)           # the connection properties\n \n  def read_delta():\n    try:\n      return spark.read.format(\"delta\").load(targetDirectory)\n    except Exception:\n      return None\n  \n  deltaTable = read_delta()\n\n  resultOutput = StringIO()\n  with redirect_stdout(resultOutput):\n    resultDF = testMethod(spark, targetDirectory)\n  resultOutput = resultOutput.getvalue()\n  \n  correctOutput = StringIO()\n  with redirect_stdout(correctOutput):\n    correctDF.show(10, truncate=False)\n  correctOutput = correctOutput.getvalue()\n  \n  updateSourceDataInDevMode(correctDF, \"bronze/investors\")\n\n  tests = TestSuite()\n\n  tests.addTest(TestCase(id=\"PCF-03B-A\", description = \"Returns correct schema\", \n           testFunction = lambda: compareSchemas(resultDF.schema, correctDF.schema, testColumnOrder=False, testNullable=False))),\n  tests.addTest(TestCase(id=\"PCF-03B-B\", description = \"Returns DataFrame with correct number of rows\",              \n           testFunction = lambda: resultDF.count() == correctDF.count())),\n  tests.addTest(TestCase(id=\"PCF-03B-C\", description = \"Returns DataFrame with correct results\", \n           testFunction = lambda: compareDataFramesLimited(resultDF, correctDF))),\n  tests.addTest(TestCase(id=\"PCF-03B-D\", description = \"Prints expected output\", \n           testFunction = lambda: correctOutput in resultOutput and resultOutput in correctOutput)),\n  tests.addTest(TestCase(id=\"PCF-03B-E\", description = \"Delta table in place\",\n           testFunction = lambda: deltaTable is not None)),\n  tests.addTest(TestCase(id=\"PCF-03B-F\", description = \"Delta table has correct content\",\n           testFunction = lambda: compareDataFramesLimited(deltaTable, correctDF)))\n\n  tests.displayResults()\n  \ndisplayHTML(\"\"\"\nDeclared the following function:\n  <li><span style=\"color:green; font-weight:bold\">realityCheck</span></li>\n\"\"\")", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "ec2a4ec8-34e9-45b2-aafb-73d22b7e86cc", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "ee5f82c1-dcfe-434d-9bbc-99b55652af6a", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 7, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "jdbcURL = sc._jvm.com.databricks.training.ClassroomDB.jdbcURL(spark._jsparkSession)\ndbProps = dict(sc._jvm.java.util.HashMap(sc._jvm.com.databricks.training.ClassroomDB.dbProps()))\n\ndisplayHTML(\"\"\"\n<h3>JDBC Connection Properties:</h3>\n<pre>\n  JDBC URL = {jdbcURL!r}\n  Connection Properties: = {dbProps!r}\n</pre>\n\"\"\".format(**globals()))", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "5dafd158-007b-4583-96db-20e724b8e40d", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "3cb18465-5e77-4310-9781-05885f3d11a3", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 8, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}, {"bindings": {}, "collapsed": false, "command": "displayHTML(\"All done!\")\n", "commandTitle": "", "commandType": "auto", "commandVersion": 0, "commentThread": [], "commentsVisible": false, "customPlotOptions": {}, "datasetPreviewNameToCmdIdMap": {}, "diffDeletes": [], "diffInserts": [], "displayType": "table", "error": null, "errorSummary": null, "finishTime": 0, "globalVars": {}, "guid": "035b062d-7e05-494b-a0c6-4c0500ce1549", "height": "auto", "hideCommandCode": false, "hideCommandResult": false, "iPythonMetadata": null, "inputWidgets": {}, "latestUser": "", "latestUserId": null, "nuid": "24b2b0ab-db66-4ad0-aec5-6d93c4a5af27", "origId": 0, "parentHierarchy": [], "pivotAggregation": null, "pivotColumns": null, "position": 9, "results": null, "showCommandTitle": false, "startTime": 0, "state": "finished", "streamStates": {}, "submitTime": 0, "subtype": "command", "version": "CommandV1", "width": "auto", "workflows": [], "xColumns": null, "yColumns": null}], "dashboards": [], "globalVars": {}, "guid": "d662e40e-6b7b-40ee-9470-315a05c8cfdf", "iPythonMetadata": null, "inputWidgets": {}, "language": "python", "name": "PCF-03B-ClassroomSetup", "origId": 0, "version": "NotebookV1"}